Delivered-To: brucelu2013@gmail.com
Received: by 2002:a67:d80b:0:0:0:0:0 with SMTP id e11csp335926vsj;
        Fri, 10 Jul 2020 02:39:30 -0700 (PDT)
X-Google-Smtp-Source: ABdhPJxWPnshf2hI/mvV3FhyxCU9VDV4QY9CwqAQ1HXy21E6tNS/DAnsi0WxEmVT6PORJLUFISjV
X-Received: by 2002:a05:620a:2284:: with SMTP id o4mr38148590qkh.115.1594373970348;
        Fri, 10 Jul 2020 02:39:30 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1594373970; cv=none;
        d=google.com; s=arc-20160816;
        b=M3HpZ9zBqAlBiQySAT9apPjav2UVQNa1gSI2r+8yfaIZZtMGuTOklgAHpniptU7Cyl
         gTUeRqNAXEOdAaZ0pRpwBFeN/tNlMDaltZWaXxCs7ESVlMDLaoHwNgvvejL2sYmfkqQt
         QDIQjj9QJqboRrbkll5V/lVnW4vwjkIv+i9X3UgkuUw0RPYwRR4j4GQBHj8PFwnmluDi
         65aN49ccMLlRfxLPbhS4y8NHxWLpY/WEUIl0c/T3JEFbuqV0vRBZkaLrDb7dnDJK7AUK
         MLHC9YkeZ/aPYGDHAa99xlum+W/ujIYQunhpqXvW8gu2I7KyeftNSdnHblIDnQH/CfvQ
         Dh8A==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=subject:to:reply-to:from:precedence:message-id:date;
        bh=x2OE5FL+tHzPZfw9Y5zFhqs+uRcWYuL4FdPzXs490Ig=;
        b=PzeNyeenT9JsdjCdsRhzqRL9A5PB0+YAkkdnrH7hQVyaGcFLNLKMclcNhStzxKz2Oa
         4eYpLjXzvWVu8bR270MaZeGjGbkKeDm35DvUpy9WvumSCPd5Y7WfoDrLV42i0ikyl20L
         4e7W5iul8Odvqj+v1L9YATefpuhxncdDSO1MeQPzVfZRS8ivp3J/QEPJGxBEZGLfCFv9
         fpdvLbMIKq2VP3smh6kq9LX5rYN6wcM0MPhlR+IUq61iSuMviF/SSr5jyZADICvkeIXZ
         By8AhWOlmmfngTLNoIhasLMh7QTFHmMXpJwFWZLo4vvfevhcwW8osYBGWMsNIfbVx/TM
         BiIw==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: domain of no-reply@arxiv.org designates 128.84.4.11 as permitted sender) smtp.mailfrom=no-reply@arxiv.org;
       dmarc=pass (p=NONE sp=NONE dis=NONE) header.from=arxiv.org
Return-Path: <no-reply@arxiv.org>
Received: from lib-arxiv-015.serverfarm.cornell.edu (mail.arxiv.org. [128.84.4.11])
        by mx.google.com with ESMTPS id t16si3787700qvy.6.2020.07.10.02.39.29
        for <brucelu2013@gmail.com>
        (version=TLS1_2 cipher=ECDHE-ECDSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 10 Jul 2020 02:39:30 -0700 (PDT)
Received-SPF: pass (google.com: domain of no-reply@arxiv.org designates 128.84.4.11 as permitted sender) client-ip=128.84.4.11;
Authentication-Results: mx.google.com;
       spf=pass (google.com: domain of no-reply@arxiv.org designates 128.84.4.11 as permitted sender) smtp.mailfrom=no-reply@arxiv.org;
       dmarc=pass (p=NONE sp=NONE dis=NONE) header.from=arxiv.org
Received: from lib-arxiv-007.serverfarm.cornell.edu (lib-arxiv-007.serverfarm.cornell.edu [128.84.4.12])
	by lib-arxiv-015.serverfarm.cornell.edu (8.14.4/8.14.4) with ESMTP id 06A9dTKb055139;
	Fri, 10 Jul 2020 05:39:29 -0400
Received: from lib-arxiv-007.serverfarm.cornell.edu (localhost [127.0.0.1])
	by lib-arxiv-007.serverfarm.cornell.edu (8.14.4/8.14.4) with ESMTP id 06A9dTcG012720;
	Fri, 10 Jul 2020 05:39:29 -0400
Received: (from e-prints@localhost)
	by lib-arxiv-007.serverfarm.cornell.edu (8.14.4/8.14.4/Submit) id 06A9dTeU012719;
	Fri, 10 Jul 2020 05:39:29 -0400
Date: Fri, 10 Jul 2020 05:39:29 -0400
Message-Id: <202007100939.06A9dTeU012719@lib-arxiv-007.serverfarm.cornell.edu>
X-Authentication-Warning: lib-arxiv-007.serverfarm.cornell.edu: e-prints set sender to no-reply@arXiv.org using -f
Precedence: bulk
From: no-reply@arXiv.org (send mail ONLY to cs)
Reply-To: cs@arXiv.org
To: rabble@arXiv.org (cs daily title/abstract distribution)
Subject: cs daily Subj-class mailing 6890 1
Content-Type: text/plain
MIME-Version: 1.0

------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Computational Geometry
Computer Vision and Pattern Recognition
Discrete Mathematics
Emerging Technologies
Graphics
 received from  Wed  8 Jul 20 18:00:00 GMT  to  Thu  9 Jul 20 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2007.04316
Date: Wed, 8 Jul 2020 16:34:25 GMT   (14189kb,D)

Title: The UU-Net: Reversible Face De-Identification for Visual Surveillance
  Video Footage
Authors: Hugo Proen\c{c}a
Categories: cs.CV
Comments: 12 pages, 4 tables, 10 figures
\\
  We propose a reversible face de-identification method for low resolution
video data, where landmark-based techniques cannot be reliably used. Our
solution is able to generate a photo realistic de-identified stream that meets
the data protection regulations and can be publicly released under minimal
privacy constraints. Notably, such stream encapsulates all the information
required to later reconstruct the original scene, which is useful for
scenarios, such as crime investigation, where the identification of the
subjects is of most importance. We describe a learning process that jointly
optimizes two main components: 1) a public module, that receives the raw data
and generates the de-identified stream, where the ID information is surrogated
in a photo-realistic and seamless way; and 2) a private module, designed for
legal/security authorities, that analyses the public stream and reconstructs
the original scene, disclosing the actual IDs of all the subjects in the scene.
The proposed solution is landmarks-free and uses a conditional generative
adversarial network to generate synthetic faces that preserve pose, lighting,
background information and even facial expressions. Also, we enable full
control over the set of soft facial attributes that should be preserved between
the raw and de-identified data, which broads the range of applications for this
solution. Our experiments were conducted in three different visual surveillance
datasets (BIODI, MARS and P-DESTRE) and showed highly encouraging results. The
source code is available at https://github.com/hugomcp/uu-net.
\\ ( https://arxiv.org/abs/2007.04316 ,  14189kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04349
Date: Wed, 8 Jul 2020 18:09:40 GMT   (3760kb,D)

Title: Deep Placental Vessel Segmentation for Fetoscopic Mosaicking
Authors: Sophia Bano, Francisco Vasconcelos, Luke M. Shepherd, Emmanuel Vander
  Poorten, Tom Vercauteren, Sebastien Ourselin, Anna L. David, Jan Deprest and
  Danail Stoyanov
Categories: cs.CV cs.LG eess.IV
Comments: Accepted at MICCAI 2020
\\
  During fetoscopic laser photocoagulation, a treatment for twin-to-twin
transfusion syndrome (TTTS), the clinician first identifies abnormal placental
vascular connections and laser ablates them to regulate blood flow in both
fetuses. The procedure is challenging due to the mobility of the environment,
poor visibility in amniotic fluid, occasional bleeding, and limitations in the
fetoscopic field-of-view and image quality. Ideally, anastomotic placental
vessels would be automatically identified, segmented and registered to create
expanded vessel maps to guide laser ablation, however, such methods have yet to
be clinically adopted. We propose a solution utilising the U-Net architecture
for performing placental vessel segmentation in fetoscopic videos. The obtained
vessel probability maps provide sufficient cues for mosaicking alignment by
registering consecutive vessel maps using the direct intensity-based technique.
Experiments on 6 different in vivo fetoscopic videos demonstrate that the
vessel intensity-based registration outperformed image intensity-based
registration approaches showing better robustness in qualitative and
quantitative comparison. We additionally reduce drift accumulation to
negligible even for sequences with up to 400 frames and we incorporate a scheme
for quantifying drift error in the absence of the ground-truth. Our paper
provides a benchmark for fetoscopy placental vessel segmentation and
registration by contributing the first in vivo vessel segmentation and
fetoscopic videos dataset.
\\ ( https://arxiv.org/abs/2007.04349 ,  3760kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04350
Date: Wed, 8 Jul 2020 18:09:54 GMT   (788kb)

Title: Sensor Fusion of Camera and Cloud Digital Twin Information for
  Intelligent Vehicles
Authors: Yongkang Liu, Ziran Wang, Kyungtae Han, Zhenyu Shou, Prashant Tiwari,
  and John H. L. Hansen
Categories: cs.CV cs.HC
Comments: Accepted by the 31st IEEE Intelligent Vehicles Symposium
\\
  With the rapid development of intelligent vehicles and Advanced Driving
Assistance Systems (ADAS), a mixed level of human driver engagements is
involved in the transportation system. Visual guidance for drivers is essential
under this situation to prevent potential risks. To advance the development of
visual guidance systems, we introduce a novel sensor fusion methodology,
integrating camera image and Digital Twin knowledge from the cloud. Target
vehicle bounding box is drawn and matched by combining results of object
detector running on ego vehicle and position information from the cloud. The
best matching result, with a 79.2% accuracy under 0.7 Intersection over Union
(IoU) threshold, is obtained with depth image served as an additional feature
source. Game engine-based simulation results also reveal that the visual
guidance system could improve driving safety significantly cooperate with the
cloud Digital Twin system.
\\ ( https://arxiv.org/abs/2007.04350 ,  788kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04364
Date: Wed, 8 Jul 2020 18:44:15 GMT   (1292kb,D)

Title: Temporal aggregation of audio-visual modalities for emotion recognition
Authors: Andreea Birhala, Catalin Nicolae Ristea, Anamaria Radoi, Liviu
  Cristian Dutu
Categories: cs.CV cs.AI
\\
  Emotion recognition has a pivotal role in affective computing and in
human-computer interaction. The current technological developments lead to
increased possibilities of collecting data about the emotional state of a
person. In general, human perception regarding the emotion transmitted by a
subject is based on vocal and visual information collected in the first seconds
of interaction with the subject. As a consequence, the integration of verbal
(i.e., speech) and non-verbal (i.e., image) information seems to be the
preferred choice in most of the current approaches towards emotion recognition.
In this paper, we propose a multimodal fusion technique for emotion recognition
based on combining audio-visual modalities from a temporal window with
different temporal offsets for each modality. We show that our proposed method
outperforms other methods from the literature and human accuracy rating. The
experiments are conducted over the open-access multimodal dataset CREMA-D.
\\ ( https://arxiv.org/abs/2007.04364 ,  1292kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04383
Date: Wed, 8 Jul 2020 19:17:14 GMT   (1493kb,D)

Title: Words as Art Materials: Generating Paintings with Sequential GANs
Authors: Azmi Can \"Ozgen, Haz{\i}m Kemal Ekenel
Categories: cs.CV eess.IV
\\
  Converting text descriptions into images using Generative Adversarial
Networks has become a popular research area. Visually appealing images have
been generated successfully in recent years. Inspired by these studies, we
investigated the generation of artistic images on a large variance dataset.
This dataset includes images with variations, for example, in shape, color, and
content. These variations in images provide originality which is an important
factor for artistic essence. One major characteristic of our work is that we
used keywords as image descriptions, instead of sentences. As the network
architecture, we proposed a sequential Generative Adversarial Network model.
The first stage of this sequential model processes the word vectors and creates
a base image whereas the next stages focus on creating high-resolution
artistic-style images without working on word vectors. To deal with the
unstable nature of GANs, we proposed a mixture of techniques like Wasserstein
loss, spectral normalization, and minibatch discrimination. Ultimately, we were
able to generate painting images, which have a variety of styles. We evaluated
our results by using the Fr\'echet Inception Distance score and conducted a
user study with 186 participants.
\\ ( https://arxiv.org/abs/2007.04383 ,  1493kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04389
Date: Wed, 8 Jul 2020 19:33:18 GMT   (3390kb,D)

Title: Quaternion Capsule Networks
Authors: Bar{\i}\c{s} \"Ozcan, Furkan K{\i}nl{\i}, Furkan K{\i}ra\c{c}
Categories: cs.CV cs.LG
\\
  Capsules are grouping of neurons that allow to represent sophisticated
information of a visual entity such as pose and features. In the view of this
property, Capsule Networks outperform CNNs in challenging tasks like object
recognition in unseen viewpoints, and this is achieved by learning the
transformations between the object and its parts with the help of high
dimensional representation of pose information. In this paper, we present
Quaternion Capsules (QCN) where pose information of capsules and their
transformations are represented by quaternions. Quaternions are immune to the
gimbal lock, have straightforward regularization of the rotation representation
for capsules, and require less number of parameters than matrices. The
experimental results show that QCNs generalize better to novel viewpoints with
fewer parameters, and also achieve on-par or better performances with the
state-of-the-art Capsule architectures on well-known benchmarking datasets.
\\ ( https://arxiv.org/abs/2007.04389 ,  3390kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04422
Date: Wed, 8 Jul 2020 20:41:52 GMT   (5118kb,D)

Title: IQ-VQA: Intelligent Visual Question Answering
Authors: Vatsal Goel, Mohit Chandak, Ashish Anand and Prithwijit Guha
Categories: cs.CV cs.CL
\\
  Even though there has been tremendous progress in the field of Visual
Question Answering, models today still tend to be inconsistent and brittle. To
this end, we propose a model-independent cyclic framework which increases
consistency and robustness of any VQA architecture. We train our models to
answer the original question, generate an implication based on the answer and
then also learn to answer the generated implication correctly. As a part of the
cyclic framework, we propose a novel implication generator which can generate
implied questions from any question-answer pair. As a baseline for future works
on consistency, we provide a new human annotated VQA-Implications dataset. The
dataset consists of ~30k questions containing implications of 3 types - Logical
Equivalence, Necessary Condition and Mutual Exclusion - made from the VQA v2.0
validation dataset. We show that our framework improves consistency of VQA
models by ~15% on the rule-based dataset, ~7% on VQA-Implications dataset and
robustness by ~2%, without degrading their performance. In addition, we also
quantitatively show improvement in attention maps which highlights better
multi-modal understanding of vision and language.
\\ ( https://arxiv.org/abs/2007.04422 ,  5118kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04449
Date: Wed, 8 Jul 2020 21:38:29 GMT   (798kb,D)

Title: Searching for Efficient Architecture for Instrument Segmentation in
  Robotic Surgery
Authors: Daniil Pakhomov, Nassir Navab
Categories: cs.CV eess.IV
Comments: MICCAI 2020
\\
  Segmentation of surgical instruments is an important problem in
robot-assisted surgery: it is a crucial step towards full instrument pose
estimation and is directly used for masking of augmented reality overlays
during surgical procedures. Most applications rely on accurate real-time
segmentation of high-resolution surgical images. While previous research
focused primarily on methods that deliver high accuracy segmentation masks,
majority of them can not be used for real-time applications due to their
computational cost. In this work, we design a light-weight and highly-efficient
deep residual architecture which is tuned to perform real-time inference of
high-resolution images. To account for reduced accuracy of the discovered
light-weight deep residual network and avoid adding any additional
computational burden, we perform a differentiable search over dilation rates
for residual units of our network. We test our discovered architecture on the
EndoVis 2017 Robotic Instruments dataset and verify that our model is the
state-of-the-art in terms of speed and accuracy tradeoff with a speed of up to
125 FPS on high resolution images.
\\ ( https://arxiv.org/abs/2007.04449 ,  798kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04505
Date: Thu, 9 Jul 2020 01:39:39 GMT   (476kb,D)

Title: Towards Unsupervised Learning for Instrument Segmentation in Robotic
  Surgery with Cycle-Consistent Adversarial Networks
Authors: Daniil Pakhomov, Wei Shen, Nassir Navab
Categories: cs.CV
Comments: IROS 2020
\\
  Surgical tool segmentation in endoscopic images is an important problem: it
is a crucial step towards full instrument pose estimation and it is used for
integration of pre- and intra-operative images into the endoscopic view. While
many recent approaches based on convolutional neural networks have shown great
results, a key barrier to progress lies in the acquisition of a large number of
manually-annotated images which is necessary for an algorithm to generalize and
work well in diverse surgical scenarios. Unlike the surgical image data itself,
annotations are difficult to acquire and may be of variable quality. On the
other hand, synthetic annotations can be automatically generated by using
forward kinematic model of the robot and CAD models of tools by projecting them
onto an image plane. Unfortunately, this model is very inaccurate and cannot be
used for supervised learning of image segmentation models. Since generated
annotations will not directly correspond to endoscopic images due to errors, we
formulate the problem as an unpaired image-to-image translation where the goal
is to learn the mapping between an input endoscopic image and a corresponding
annotation using an adversarial model. Our approach allows to train image
segmentation models without the need to acquire expensive annotations and can
potentially exploit large unlabeled endoscopic image collection outside the
annotated distributions of image/annotation data. We test our proposed method
on Endovis 2017 challenge dataset and show that it is competitive with
supervised segmentation methods.
\\ ( https://arxiv.org/abs/2007.04505 ,  476kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04514
Date: Thu, 9 Jul 2020 02:29:34 GMT   (4600kb,D)

Title: Deep Multi-task Learning for Facial Expression Recognition and Synthesis
  Based on Selective Feature Sharing
Authors: Rui Zhao, Tianshan Liu, Jun Xiao, Daniel P.K. Lun, Kin-Man Lam
Categories: cs.CV
Comments: ICPR 2020
\\
  Multi-task learning is an effective learning strategy for deep-learning-based
facial expression recognition tasks. However, most existing methods take into
limited consideration the feature selection, when transferring information
between different tasks, which may lead to task interference when training the
multi-task networks. To address this problem, we propose a novel selective
feature-sharing method, and establish a multi-task network for facial
expression recognition and facial expression synthesis. The proposed method can
effectively transfer beneficial features between different tasks, while
filtering out useless and harmful information. Moreover, we employ the facial
expression synthesis task to enlarge and balance the training dataset to
further enhance the generalization ability of the proposed method. Experimental
results show that the proposed method achieves state-of-the-art performance on
those commonly used facial expression recognition benchmarks, which makes it a
potential solution to real-world facial expression recognition problems.
\\ ( https://arxiv.org/abs/2007.04514 ,  4600kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04515
Date: Thu, 9 Jul 2020 02:30:48 GMT   (1437kb,D)

Title: Aligning Videos in Space and Time
Authors: Senthil Purushwalkam, Tian Ye, Saurabh Gupta, Abhinav Gupta
Categories: cs.CV
Comments: To appear at the European Conference on Computer Vision (ECCV) 2020
\\
  In this paper, we focus on the task of extracting visual correspondences
across videos. Given a query video clip from an action class, we aim to align
it with training videos in space and time. Obtaining training data for such a
fine-grained alignment task is challenging and often ambiguous. Hence, we
propose a novel alignment procedure that learns such correspondence in space
and time via cross video cycle-consistency. During training, given a pair of
videos, we compute cycles that connect patches in a given frame in the first
video by matching through frames in the second video. Cycles that connect
overlapping patches together are encouraged to score higher than cycles that
connect non-overlapping patches. Our experiments on the Penn Action and Pouring
datasets demonstrate that the proposed method can successfully learn to
correspond semantically similar patches across videos, and learns
representations that are sensitive to object and action states.
\\ ( https://arxiv.org/abs/2007.04515 ,  1437kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04525
Date: Thu, 9 Jul 2020 03:06:06 GMT   (6748kb,D)

Title: PointMask: Towards Interpretable and Bias-Resilient Point Cloud
  Processing
Authors: Saeid Asgari Taghanaki, Kaveh Hassani, Pradeep Kumar Jayaraman, Amir
  Hosein Khasahmadi, Tonya Custis
Categories: cs.CV cs.LG
Comments: Accepted to ICML 2020 WHI
\\
  Deep classifiers tend to associate a few discriminative input variables with
their objective function, which in turn, may hurt their generalization
capabilities. To address this, one can design systematic experiments and/or
inspect the models via interpretability methods. In this paper, we investigate
both of these strategies on deep models operating on point clouds. We propose
PointMask, a model-agnostic interpretable information-bottleneck approach for
attribution in point cloud models. PointMask encourages exploring the majority
of variation factors in the input space while gradually converging to a general
solution. More specifically, PointMask introduces a regularization term that
minimizes the mutual information between the input and the latent features used
to masks out irrelevant variables. We show that coupling a PointMask layer with
an arbitrary model can discern the points in the input space which contribute
the most to the prediction score, thereby leading to interpretability. Through
designed bias experiments, we also show that thanks to its gradual masking
feature, our proposed method is effective in handling data bias.
\\ ( https://arxiv.org/abs/2007.04525 ,  6748kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04536
Date: Thu, 9 Jul 2020 03:31:33 GMT   (550kb,D)

Title: Attention-based Residual Speech Portrait Model for Speech to Face
  Generation
Authors: Jianrong Wang, Xiaosheng Hu, Li Liu, Wei Liu, Mei Yu, Tianyi Xu
Categories: cs.CV cs.LG eess.IV
\\
  Given a speaker's speech, it is interesting to see if it is possible to
generate this speaker's face. One main challenge in this task is to alleviate
the natural mismatch between face and speech. To this end, in this paper, we
propose a novel Attention-based Residual Speech Portrait Model (AR-SPM) by
introducing the ideal of the residual into a hybrid encoder-decoder
architecture, where face prior features are merged with the output of speech
encoder to form the final face feature. In particular, we innovatively
establish a tri-item loss function, which is a weighted linear combination of
the L2-norm, L1-norm and negative cosine loss, to train our model by comparing
the final face feature and true face feature. Evaluation on AVSpeech dataset
shows that our proposed model accelerates the convergence of training,
outperforms the state-of-the-art in terms of quality of the generated face, and
achieves superior recognition accuracy of gender and age compared with the
ground truth.
\\ ( https://arxiv.org/abs/2007.04536 ,  550kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04537
Date: Thu, 9 Jul 2020 03:37:31 GMT   (4205kb,D)

Title: Point Set Voting for Partial Point Cloud Analysis
Authors: Junming Zhang, Weijia Chen, Yuping Wang, Ram Vasudevan, Matthew
  Johnson-Roberson
Categories: cs.CV cs.RO
\\
  The continual improvement of 3D sensors has driven the development of
algorithms to perform point cloud analysis. In fact, techniques for point cloud
classification and segmentation have in recent years achieved incredible
performance driven in part by leveraging large synthetic datasets.
Unfortunately these same state-of-the-art approaches perform poorly when
applied to incomplete point clouds. This limitation of existing algorithms is
particularly concerning since point clouds generated by 3D sensors in the real
world are usually incomplete due to perspective view or occlusion by other
objects. This paper proposes a general model for partial point clouds analysis
wherein the latent feature encoding a complete point clouds is inferred by
applying a local point set voting strategy. In particular, each local point set
constructs a vote that corresponds to a distribution in the latent space, and
the optimal latent feature is the one with the highest probability. This
approach ensures that any subsequent point cloud analysis is robust to partial
observation while simultaneously guaranteeing that the proposed model is able
to output multiple possible results. This paper illustrates that this proposed
method achieves state-of-the-art performance on shape classification, part
segmentation and point cloud completion.
\\ ( https://arxiv.org/abs/2007.04537 ,  4205kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04538
Date: Thu, 9 Jul 2020 03:39:09 GMT   (3894kb,D)

Title: EPI-based Oriented Relation Networks for Light Field Depth Estimation
Authors: Kunyuan Li, Jun Zhang, Rui Sun, Xudong Zhang, Jun Gao
Categories: cs.CV
\\
  Light fields record not only the spatial information of observed scenes but
also the directions of all incoming light rays. The spatial information and
angular information implicitly contain the geometrical characteristics such as
multi-view geometry or epipolar geometry, which can be exploited to improve the
performance of depth estimation. Epipolar Plane Image (EPI), the unique 2D
spatial-angular slice of the light field, contains patterns of oriented lines.
The slope of these lines is associated with the disparity. Benefit from this
property of EPIs, some representative methods estimate depth maps by analyzing
the disparity of each line in EPIs. However, these methods often extract the
optimal slope of the lines from EPIs while ignoring the relationship between
neighboring pixels, which leads to inaccurate depth map predictions. Based on
the observation that the similar linear structure between the oriented lines
and their neighboring pixels, we propose an end-to-end fully convolutional
network (FCN) to estimate the depth value of the intersection point on the
horizontal and vertical EPIs. Specifically, we present a new feature extraction
module, called Oriented Relation Module (ORM), that constructs the relationship
between the line orientations. To facilitate training, we also propose a
refocusing-based data augmentation method to obtain different slopes from EPIs
of the same scene point. Extensive experiments verify the efficacy of learning
relations and show that our approach is competitive to other state-of-the-art
methods.
\\ ( https://arxiv.org/abs/2007.04538 ,  3894kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04543
Date: Thu, 9 Jul 2020 03:53:33 GMT   (9437kb,D)

Title: Long-Term Residual Blending Network for Blur Invariant Single Image
  Blind deblurring
Authors: Sungkwon An, Hyungmin Roh and Myungjoo Kang
Categories: cs.CV
Comments: 9 pages, 7 figures
ACM-class: I.4.3
\\
  We present a novel, blind, single image deblurring method that utilizes
information regarding blur kernels. Our model solves the deblurring problem by
dividing it into two successive tasks: (1) blur kernel estimation and (2) sharp
image restoration. We first introduce a kernel estimation network that produces
adaptive blur kernels based on the analysis of the blurred image. The network
learns the blur pattern of the input image and trains to generate the
estimation of image-specific blur kernels. Subsequently, we propose a long-term
residual blending network that restores sharp images using the estimated blur
kernel. To use the kernel efficiently, we propose a blending block that encodes
features from both blurred images and blur kernels into a low dimensional space
and then decodes them simultaneously to obtain an appropriately synthesized
feature representation. We evaluate our model on REDS, GOPRO and Flickr2K
datasets using various Gaussian blur kernels. Experiments show that our model
can achieve excellent results on each dataset.
\\ ( https://arxiv.org/abs/2007.04543 ,  9437kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04557
Date: Thu, 9 Jul 2020 05:02:23 GMT   (3057kb,D)

Title: Alleviating the Burden of Labeling: Sentence Generation by Attention
  Branch Encoder-Decoder Network
Authors: Tadashi Ogura, Aly Magassouba, Komei Sugiura, Tsubasa Hirakawa,
  Takayoshi Yamashita, Hironobu Fujiyoshi, and Hisashi Kawai
Categories: cs.CV cs.RO
Comments: 9 pages, 8 figures. accepted for IEEE Robotics and Automation Letters
  (RA-L) with presentation at IROS 2020
\\
  Domestic service robots (DSRs) are a promising solution to the shortage of
home care workers. However, one of the main limitations of DSRs is their
inability to interact naturally through language. Recently, data-driven
approaches have been shown to be effective for tackling this limitation;
however, they often require large-scale datasets, which is costly. Based on
this background, we aim to perform automatic sentence generation of fetching
instructions: for example, "Bring me a green tea bottle on the table." This is
particularly challenging because appropriate expressions depend on the target
object, as well as its surroundings. In this paper, we propose the attention
branch encoder--decoder network (ABEN), to generate sentences from visual
inputs. Unlike other approaches, the ABEN has multimodal attention branches
that use subword-level attention and generate sentences based on subword
embeddings. In experiments, we compared the ABEN with a baseline method using
four standard metrics in image captioning. Results show that the ABEN
outperformed the baseline in terms of these metrics.
\\ ( https://arxiv.org/abs/2007.04557 ,  3057kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04561
Date: Thu, 9 Jul 2020 05:22:40 GMT   (1577kb,D)

Title: Auxiliary Tasks Speed Up Learning PointGoal Navigation
Authors: Joel Ye, Dhruv Batra, Erik Wijmans, Abhishek Das
Categories: cs.CV cs.LG cs.RO
Comments: 13 pages
\\
  PointGoal Navigation is an embodied task that requires agents to navigate to
a specified point in an unseen environment. Wijmans et al. showed that this
task is solvable but their method is computationally prohibitive, requiring 2.5
billion frames and 180 GPU-days. In this work, we develop a method to
significantly increase sample and time efficiency in learning PointNav using
self-supervised auxiliary tasks (e.g. predicting the action taken between two
egocentric observations, predicting the distance between two observations from
a trajectory,etc.).We find that naively combining multiple auxiliary tasks
improves sample efficiency,but only provides marginal gains beyond a point. To
overcome this, we use attention to combine representations learnt from
individual auxiliary tasks. Our best agent is 5x faster to reach the
performance of the previous state-of-the-art, DD-PPO, at 40M frames, and
improves on DD-PPO's performance at40M frames by 0.16 SPL. Our code is publicly
available at https://github.com/joel99/habitat-pointnav-aux.
\\ ( https://arxiv.org/abs/2007.04561 ,  1577kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04584
Date: Thu, 9 Jul 2020 06:47:49 GMT   (8714kb,D)

Title: VisImages: A Large-scale, High-quality Image Corpus in Visualization
  Publications
Authors: Dazhen Deng, Yihong Wu, Xinhuan Shu, Mengye Xu, Jiang Wu, Siwei Fu
  Yingcai Wu
Categories: cs.CV
\\
  Images in visualization publications contain rich information, such as novel
visual designs, model details, and experiment results. Constructing such an
image corpus can contribute to the community in many aspects, including
literature analysis from the perspective of visual representations, empirical
studies on visual memorability, and machine learning research for chart
detection. This study presents VisImages, a high-quality and large-scale image
corpus collected from visualization publications. VisImages contain fruitful
and diverse annotations for each image, including captions, types of visual
representations, and bounding boxes. First, we algorithmically extract the
images associated with captions and manually correct the errors. Second, to
categorize visualizations in publications, we extend and iteratively refine the
existing taxonomy through a multi-round pilot study. Third, guided by this
taxonomy, we invite senior visualization practitioners to annotate visual
representations that appear in each image. In this process, we borrow
techniques such as "gold standards" and majority voting for quality control.
Finally, we recruit the crowd to draw bounding boxes for visual representations
in the images. The resulting corpus contains 35,096 annotated visualizations
from 12,267 images with 12,057 captions in 1397 papers from VAST and InfoVis.
We demonstrate the usefulness of VisImages through the following four use
cases: 1) analysis of color usage in VAST and InfoVis papers across years, 2)
discussion of the researcher preference on visualization types, 3) spatial
distribution analysis of visualizations in visual analytic systems, and 4)
training visualization detection models.
\\ ( https://arxiv.org/abs/2007.04584 ,  8714kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04592
Date: Thu, 9 Jul 2020 07:03:17 GMT   (4492kb,D)

Title: Monocular Vision based Crowdsourced 3D Traffic Sign Positioning with
  Unknown Camera Intrinsics and Distortion Coefficients
Authors: Hemang Chawla, Matti Jukola, Elahe Arani, and Bahram Zonooz
Categories: cs.CV cs.LG cs.RO
Comments: Accepted at 2020 IEEE 23rd International Conference on Intelligent
  Transportation Systems (ITSC)
\\
  Autonomous vehicles and driver assistance systems utilize maps of 3D semantic
landmarks for improved decision making. However, scaling the mapping process as
well as regularly updating such maps come with a huge cost. Crowdsourced
mapping of these landmarks such as traffic sign positions provides an appealing
alternative. The state-of-the-art approaches to crowdsourced mapping use ground
truth camera parameters, which may not always be known or may change over time.
In this work, we demonstrate an approach to computing 3D traffic sign positions
without knowing the camera focal lengths, principal point, and distortion
coefficients a priori. We validate our proposed approach on a public dataset of
traffic signs in KITTI. Using only a monocular color camera and GPS, we achieve
an average single journey relative and absolute positioning accuracy of 0.26 m
and 1.38 m, respectively.
\\ ( https://arxiv.org/abs/2007.04592 ,  4492kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04639
Date: Thu, 9 Jul 2020 08:41:30 GMT   (8000kb,D)

Title: Attention Neural Network for Trash Detection on Water Channels
Authors: Mohbat Tharani, Abdul Wahab Amin, Mohammad Maaz and Murtaza Taj
Categories: cs.CV eess.IV
Comments: Object Detection, Trash Detection, Water Quality
\\
  Rivers and canals flowing through cities are often used illegally for dumping
the trash. This contaminates freshwater channels as well as causes blockage in
sewerage resulting in urban flooding. When this contaminated water reaches
agricultural fields, it results in degradation of soil and poses critical
environmental as well as economic threats. The dumped trash is often found
floating on the water surface. The trash could be disfigured, partially
submerged, decomposed into smaller pieces, clumped together with other objects
which obscure its shape and creates a challenging detection problem. This paper
proposes a method for the detection of visible trash floating on the water
surface of the canals in urban areas. We also provide a large dataset, first of
its kind, trash in water channels that contains object-level annotations. A
novel attention layer is proposed that improves the detection of smaller
objects. Towards the end of this paper, we provide a detailed comparison of our
method with state-of-the-art object detectors and show that our method
significantly improves the detection of smaller objects. The dataset will be
made publicly available.
\\ ( https://arxiv.org/abs/2007.04639 ,  8000kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04644
Date: Thu, 9 Jul 2020 08:56:28 GMT   (7237kb,D)

Title: ESA-ReID: Entropy-Based Semantic Feature Alignment for Person re-ID
Authors: Chaoping Tu, Yin Zhao, Longjun Cai
Categories: cs.CV
\\
  Person re-identification (re-ID) is a challenging task in real-world. Besides
the typical application in surveillance system, re-ID also has significant
values to improve the recall rate of people identification in content video (TV
or Movies). However, the occlusion, shot angle variations and complicated
background make it far away from application, especially in content video. In
this paper we propose an entropy based semantic feature alignment model, which
takes advantages of the detailed information of the human semantic feature.
Considering the uncertainty of semantic segmentation, we introduce a semantic
alignment with an entropy-based mask which can reduce the negative effects of
mask segmentation errors. We construct a new re-ID dataset based on content
videos with many cases of occlusion and body part missing, which will be
released in future. Extensive studies on both existing datasets and the new
dataset demonstrate the superior performance of the proposed model.
\\ ( https://arxiv.org/abs/2007.04644 ,  7237kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04646
Date: Thu, 9 Jul 2020 08:57:19 GMT   (895kb,D)

Title: JGR-P2O: Joint Graph Reasoning based Pixel-to-Offset Prediction Network
  for 3D Hand Pose Estimation from a Single Depth Image
Authors: Linpu Fang, Xingyan Liu, Li Liu, Hang Xu, and Wenxiong Kang
Categories: cs.CV
Comments: Accepted by ECCV2020 as a Spotlight paper
\\
  State-of-the-art single depth image-based 3D hand pose estimation methods are
based on dense predictions, including voxel-to-voxel predictions,
point-to-point regression, and pixel-wise estimations. Despite the good
performance, those methods have a few issues in nature, such as the poor
trade-off between accuracy and efficiency, and plain feature representation
learning with local convolutions. In this paper, a novel pixel-wise
prediction-based method is proposed to address the above issues. The key ideas
are two-fold: a) explicitly modeling the dependencies among joints and the
relations between the pixels and the joints for better local feature
representation learning; b) unifying the dense pixel-wise offset predictions
and direct joint regression for end-to-end training. Specifically, we first
propose a graph convolutional network (GCN) based joint graph reasoning module
to model the complex dependencies among joints and augment the representation
capability of each pixel. Then we densely estimate all pixels' offsets to
joints in both image plane and depth space and calculate the joints' positions
by a weighted average over all pixels' predictions, totally discarding the
complex postprocessing operations. The proposed model is implemented with an
efficient 2D fully convolutional network (FCN) backbone and has only about 1.4M
parameters. Extensive experiments on multiple 3D hand pose estimation
benchmarks demonstrate that the proposed method achieves new state-of-the-art
accuracy while running very efficiently with around a speed of 110fps on a
single NVIDIA 1080Ti GPU.
\\ ( https://arxiv.org/abs/2007.04646 ,  895kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04651
Date: Thu, 9 Jul 2020 09:19:56 GMT   (1065kb,D)

Title: Maximum Entropy Regularization and Chinese Text Recognition
Authors: Changxu Cheng, Wuheng Xu, Xiang Bai, Bin Feng, and Wenyu Liu
Categories: cs.CV
Comments: 15 pages
\\
  Chinese text recognition is more challenging than Latin text due to the large
amount of fine-grained Chinese characters and the great imbalance over classes,
which causes a serious overfitting problem. We propose to apply Maximum Entropy
Regularization to regularize the training process, which is to simply add a
negative entropy term to the canonical cross-entropy loss without any
additional parameters and modification of a model. We theoretically give the
convergence probability distribution and analyze how the regularization
influence the learning process. Experiments on Chinese character recognition,
Chinese text line recognition and fine-grained image classification achieve
consistent improvement, proving that the regularization is beneficial to
generalization and robustness of a recognition model.
\\ ( https://arxiv.org/abs/2007.04651 ,  1065kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04655
Date: Thu, 9 Jul 2020 09:26:27 GMT   (3516kb,D)

Title: Inertial Measurements for Motion Compensation in Weight-bearing
  Cone-beam CT of the Knee
Authors: Jennifer Maier, Marlies Nitschke, Jang-Hwan Choi, Garry Gold, Rebecca
  Fahrig, Bjoern M. Eskofier, Andreas Maier
Categories: cs.CV
Comments: 10 pages, 2 figures, 2 tables, accepted at MICCAI 2020
\\
  Involuntary motion during weight-bearing cone-beam computed tomography (CT)
scans of the knee causes artifacts in the reconstructed volumes making them
unusable for clinical diagnosis. Currently, image-based or marker-based methods
are applied to correct for this motion, but often require long execution or
preparation times. We propose to attach an inertial measurement unit (IMU)
containing an accelerometer and a gyroscope to the leg of the subject in order
to measure the motion during the scan and correct for it. To validate this
approach, we present a simulation study using real motion measured with an
optical 3D tracking system. With this motion, an XCAT numerical knee phantom is
non-rigidly deformed during a simulated CT scan creating motion corrupted
projections. A biomechanical model is animated with the same tracked motion in
order to generate measurements of an IMU placed below the knee. In our proposed
multi-stage algorithm, these signals are transformed to the global coordinate
system of the CT scan and applied for motion compensation during
reconstruction. Our proposed approach can effectively reduce motion artifacts
in the reconstructed volumes. Compared to the motion corrupted case, the
average structural similarity index and root mean squared error with respect to
the no-motion case improved by 13-21% and 68-70%, respectively. These results
are qualitatively and quantitatively on par with a state-of-the-art
marker-based method we compared our approach to. The presented study shows the
feasibility of this novel approach, and yields promising results towards a
purely IMU-based motion compensation in C-arm CT.
\\ ( https://arxiv.org/abs/2007.04655 ,  3516kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04657
Date: Thu, 9 Jul 2020 09:27:34 GMT   (2875kb,D)

Title: The autonomous hidden camera crew
Authors: Timothy Callemein, Wiebe Van Ranst and Toon Goedem\'e
Categories: cs.CV
Comments: 4 pages, 6 figures
DOI: 10.23919/MVA.2017.7986769
\\
  Reality TV shows that follow people in their day-to-day lives are not a new
concept. However, the traditional methods used in the industry require a lot of
manual labour and need the presence of at least one physical camera man.
Because of this, the subjects tend to behave differently when they are aware of
being recorded. This paper will present an approach to follow people in their
day-to-day lives, for long periods of time (months to years), while being as
unobtrusive as possible. To do this, we use unmanned cinematographically-aware
cameras hidden in people's houses. Our contribution in this paper is twofold:
First, we create a system to limit the amount of recorded data by intelligently
controlling a video switch matrix, in combination with a multi-channel
recorder. Second, we create a virtual camera man by controlling a PTZ camera to
automatically make cinematographically pleasing shots. Throughout this paper,
we worked closely with a real camera crew. This enabled us to compare the
results of our system to the work of trained professionals.
\\ ( https://arxiv.org/abs/2007.04657 ,  2875kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04666
Date: Thu, 9 Jul 2020 09:50:45 GMT   (770kb,D)

Title: Building Robust Industrial Applicable Object Detection Models Using
  Transfer Learning and Single Pass Deep Learning Architectures
Authors: Steven Puttemans, Timothy Callemein and Toon Goedem\'e
Categories: cs.CV
DOI: 10.5220/0006562002090217
\\
  The uprising trend of deep learning in computer vision and artificial
intelligence can simply not be ignored. On the most diverse tasks, from
recognition and detection to segmentation, deep learning is able to obtain
state-of-the-art results, reaching top notch performance. In this paper we
explore how deep convolutional neural networks dedicated to the task of object
detection can improve our industrial-oriented object detection pipelines, using
state-of-the-art open source deep learning frameworks, like Darknet. By using a
deep learning architecture that integrates region proposals, classification and
probability estimation in a single run, we aim at obtaining real-time
performance. We focus on reducing the needed amount of training data
drastically by exploring transfer learning, while still maintaining a high
average precision. Furthermore we apply these algorithms to two industrially
relevant applications, one being the detection of promotion boards in eye
tracking data and the other detecting and recognizing packages of warehouse
products for augmented advertisements.
\\ ( https://arxiv.org/abs/2007.04666 ,  770kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04671
Date: Thu, 9 Jul 2020 10:00:03 GMT   (6699kb,D)

Title: Automated analysis of eye-tracker-based human-human interaction studies
Authors: Timothy Callemein, Kristof Van Beeck, Geert Br\^one, Toon Goedem\'e
Categories: cs.CV
DOI: 10.1007/978-981-13-1056-0_50
\\
  Mobile eye-tracking systems have been available for about a decade now and
are becoming increasingly popular in different fields of application, including
marketing, sociology, usability studies and linguistics. While the
user-friendliness and ergonomics of the hardware are developing at a rapid
pace, the software for the analysis of mobile eye-tracking data in some points
still lacks robustness and functionality. With this paper, we investigate which
state-of-the-art computer vision algorithms may be used to automate the
post-analysis of mobile eye-tracking data. For the case study in this paper, we
focus on mobile eye-tracker recordings made during human-human face-to-face
interactions. We compared two recent publicly available frameworks (YOLOv2 and
OpenPose) to relate the gaze location generated by the eye-tracker to the head
and hands visible in the scene camera data. In this paper we will show that the
use of this single-pipeline framework provides robust results, which are both
more accurate and faster than previous work in the field. Moreover, our
approach does not rely on manual interventions during this process.
\\ ( https://arxiv.org/abs/2007.04671 ,  6699kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04678
Date: Thu, 9 Jul 2020 10:10:23 GMT   (5573kb,D)

Title: How low can you go? Privacy-preserving people detection with an
  omni-directional camera
Authors: Timothy Callemein, Kristof Van Beeck, and Toon Goedem\'e
Categories: cs.CV
DOI: 10.5220/0007573206300637
\\
  In this work, we use a ceiling-mounted omni-directional camera to detect
people in a room. This can be used as a sensor to measure the occupancy of
meeting rooms and count the amount of flex-desk working spaces available. If
these devices can be integrated in an embedded low-power sensor, it would form
an ideal extension of automated room reservation systems in office
environments. The main challenge we target here is ensuring the privacy of the
people filmed. The approach we propose is going to extremely low image
resolutions, such that it is impossible to recognise people or read potentially
confidential documents. Therefore, we retrained a single-shot low-resolution
person detection network with automatically generated ground truth. In this
paper, we prove the functionality of this approach and explore how low we can
go in resolution, to determine the optimal trade-off between recognition
accuracy and privacy preservation. Because of the low resolution, the result is
a lightweight network that can potentially be deployed on embedded hardware.
Such embedded implementation enables the development of a decentralised smart
camera which only outputs the required meta-data (i.e. the number of persons in
the meeting room).
\\ ( https://arxiv.org/abs/2007.04678 ,  5573kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04687
Date: Thu, 9 Jul 2020 10:29:31 GMT   (4091kb,D)

Title: Not only Look, but also Listen: Learning Multimodal Violence Detection
  under Weak Supervision
Authors: Peng Wu, Jing Liu, Yujia Shi, Yujia Sun, Fangtao Shao, Zhaoyang Wu,
  Zhiwei Yang
Categories: cs.CV
Comments: To appear in ECCV 2020
\\
  Violence detection has been studied in computer vision for years. However,
previous work are either superficial, e.g., classification of short-clips, and
the single scenario, or undersupplied, e.g., the single modality, and
hand-crafted features based multimodality. To address this problem, in this
work we first release a large-scale and multi-scene dataset named XD-Violence
with a total duration of 217 hours, containing 4754 untrimmed videos with audio
signals and weak labels. Then we propose a neural network containing three
parallel branches to capture different relations among video snippets and
integrate features, where holistic branch captures long-range dependencies
using similarity prior, localized branch captures local positional relation
using proximity prior, and score branch dynamically captures the closeness of
predicted score. Besides, our method also includes an approximator to meet the
needs of online detection. Our method outperforms other state-of-the-art
methods on our released dataset and other existing benchmark. Moreover,
extensive experimental results also show the positive effect of multimodal
input and modeling relationships. The code and dataset will be released in
https://roc-ng.github.io/XD-Violence/.
\\ ( https://arxiv.org/abs/2007.04687 ,  4091kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04690
Date: Thu, 9 Jul 2020 10:33:31 GMT   (394kb)

Title: Pollen13K: A Large Scale Microscope Pollen Grain Image Dataset
Authors: Sebastiano Battiato, Alessandro Ortis, Francesca Trenta, Lorenzo
  Ascari, Mara Politi, Consolata Siniscalco
Categories: cs.CV
Comments: This paper is a preprint of a paper accepted at the IEEE
  International Conference on Image Processing 2020
\\
  Pollen grain classification has a remarkable role in many fields from
medicine to biology and agronomy. Indeed, automatic pollen grain classification
is an important task for all related applications and areas. This work presents
the first large-scale pollen grain image dataset, including more than 13
thousands objects. After an introduction to the problem of pollen grain
classification and its motivations, the paper focuses on the employed data
acquisition steps, which include aerobiological sampling, microscope image
acquisition, object detection, segmentation and labelling. Furthermore, a
baseline experimental assessment for the task of pollen classification on the
built dataset, together with discussion on the achieved results, is presented.
\\ ( https://arxiv.org/abs/2007.04690 ,  394kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04717
Date: Thu, 9 Jul 2020 11:36:48 GMT   (690kb,D)

Title: Animated GIF optimization by adaptive color local table management
Authors: Oliver Giudice (1 and 2), Dario Allegra (1), Francesco Guarnera (1 and
  2), Filippo Stanco (1), Sebastiano Battiato (1 and 2) ((1) University of
  Catania, (2) iCTLab s.r.l. - Spin-off of University of Catania)
Categories: cs.CV
\\
  After thirty years of the GIF file format, today is becoming more popular
than ever: being a great way of communication for friends and communities on
Instant Messengers and Social Networks. While being so popular, the original
compression method to encode GIF images have not changed a bit. On the other
hand popularity means that storage saving becomes an issue for hosting
platforms. In this paper a parametric optimization technique for animated GIFs
will be presented. The proposed technique is based on Local Color Table
selection and color remapping in order to create optimized animated GIFs while
preserving the original format. The technique achieves good results in terms of
byte reduction with limited or no loss of perceived color quality. Tests
carried out on 1000 GIF files demonstrate the effectiveness of the proposed
optimization strategy.
\\ ( https://arxiv.org/abs/2007.04717 ,  690kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04755
Date: Thu, 9 Jul 2020 13:05:32 GMT   (7625kb,D)

Title: Generalized Many-Way Few-Shot Video Classification
Authors: Yongqin Xian, Bruno Korbar, Matthijs Douze, Bernt Schiele, Zeynep
  Akata, Lorenzo Torresani
Categories: cs.CV
\\
  Few-shot learning methods operate in low data regimes. The aim is to learn
with few training examples per class. Although significant progress has been
made in few-shot image classification, few-shot video recognition is relatively
unexplored and methods based on 2D CNNs are unable to learn temporal
information. In this work we thus develop a simple 3D CNN baseline, surpassing
existing methods by a large margin. To circumvent the need of labeled examples,
we propose to leverage weakly-labeled videos from a large dataset using tag
retrieval followed by selecting the best clips with visual similarities,
yielding further improvement. Our results saturate current 5-way benchmarks for
few-shot video classification and therefore we propose a new challenging
benchmark involving more classes and a mixture of classes with varying
supervision.
\\ ( https://arxiv.org/abs/2007.04755 ,  7625kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04793
Date: Wed, 8 Jul 2020 00:46:43 GMT   (6017kb,D)

Title: Statistical shape analysis of brain arterial networks (BAN)
Authors: Xiaoyang Guo, Aditi Basu Bal, Tom Needham, Anuj Srivastava
Categories: cs.CV math.DG stat.AP
Comments: arXiv admin note: substantial text overlap with arXiv:2003.00287
\\
  Structures of brain arterial networks (BANs) - that are complex arrangements
of individual arteries, their branching patterns, and inter-connectivities -
play an important role in characterizing and understanding brain physiology.
One would like tools for statistically analyzing the shapes of BANs, i.e.
quantify shape differences, compare population of subjects, and study the
effects of covariates on these shapes. This paper mathematically represents and
statistically analyzes BAN shapes as elastic shape graphs. Each elastic shape
graph is made up of nodes that are connected by a number of 3D curves, and
edges, with arbitrary shapes. We develop a mathematical representation, a
Riemannian metric and other geometrical tools, such as computations of
geodesics, means and covariances, and PCA for analyzing elastic graphs and
BANs. This analysis is applied to BANs after separating them into four
components -- top, bottom, left, and right. This framework is then used to
generate shape summaries of BANs from 92 subjects, and to study the effects of
age and gender on shapes of BAN components. We conclude that while gender
effects require further investigation, the age has a clear, quantifiable effect
on BAN shapes. Specifically, we find an increased variance in BAN shapes as age
increases.
\\ ( https://arxiv.org/abs/2007.04793 ,  6017kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04865
Date: Thu, 9 Jul 2020 15:05:44 GMT   (9411kb,D)

Title: A Deep Joint Sparse Non-negative Matrix Factorization Framework for
  Identifying the Common and Subject-specific Functional Units of Tongue Motion
  During Speech
Authors: Jonghye Woo, Fangxu Xing, Jerry L. Prince, Maureen Stone, Arnold
  Gomez, Timothy G. Reese, Van J. Wedeen, Georges El Fakhri
Categories: cs.CV eess.IV
\\
  Intelligible speech is produced by creating varying internal local muscle
groupings---i.e., functional units---that are generated in a systematic and
coordinated manner. There are two major challenges in characterizing and
analyzing functional units. First, due to the complex and convoluted nature of
tongue structure and function, it is of great importance to develop a method
that can accurately decode complex muscle coordination patterns during speech.
Second, it is challenging to keep identified functional units across subjects
comparable due to their substantial variability. In this work, to address these
challenges, we develop a new deep learning framework to identify common and
subject-specific functional units of tongue motion during speech. Our framework
hinges on joint deep graph-regularized sparse non-negative matrix factorization
(NMF) using motion quantities derived from displacements by tagged Magnetic
Resonance Imaging. More specifically, we transform NMF with sparse and manifold
regularizations into modular architectures akin to deep neural networks by
means of unfolding the Iterative Shrinkage-Thresholding Algorithm to learn
interpretable building blocks and associated weighting map. We then apply
spectral clustering to common and subject-specific functional units.
Experiments carried out with simulated datasets show that the proposed method
surpasses the comparison methods. Experiments carried out with in vivo tongue
motion datasets show that the proposed method can determine the common and
subject-specific functional units with increased interpretability and decreased
size variability.
\\ ( https://arxiv.org/abs/2007.04865 ,  9411kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04883
Date: Thu, 9 Jul 2020 15:35:10 GMT   (11086kb,D)

Title: PIE-NET: Parametric Inference of Point Cloud Edges
Authors: Xiaogang Wang (1 and 2), Yuelang Xu (5 and 2), Kai Xu (3), Andrea
  Tagliasacchi (4), Bin Zhou (1), Ali Mahdavi-Amiri (2), Hao Zhang (2) ((1)
  Beihang University, (2) Simon Fraser University, (3) National University of
  Defense Technology, (4) Google Research, (5) Tsinghua University)
Categories: cs.CV
\\
  We introduce an end-to-end learnable technique to robustly identify feature
edges in 3D point cloud data. We represent these edges as a collection of
parametric curves (i.e.,lines, circles, and B-splines). Accordingly, our deep
neural network, coined PIE-NET, is trained for parametric inference of edges.
The network relies on a "region proposal" architecture, where a first module
proposes an over-complete collection of edge and corner points, and a second
module ranks each proposal to decide whether it should be considered. We train
and evaluate our method on the ABC dataset, a large dataset of CAD models, and
compare our results to those produced by traditional (non-learning) processing
pipelines, as well as a recent deep learning based edge detector (EC-NET). Our
results significantly improve over the state-of-the-art from both a
quantitative and qualitative standpoint.
\\ ( https://arxiv.org/abs/2007.04883 ,  11086kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04901
Date: Thu, 9 Jul 2020 16:01:44 GMT   (4777kb,D)

Title: Cross-Modal Weighting Network for RGB-D Salient Object Detection
Authors: Gongyang Li, Zhi Liu, Linwei Ye, Yang Wang, Haibin Ling
Categories: cs.CV
Comments: Accepted in ECCV2020. Code: https://github.com/MathLee/CMWNet
\\
  Depth maps contain geometric clues for assisting Salient Object Detection
(SOD). In this paper, we propose a novel Cross-Modal Weighting (CMW) strategy
to encourage comprehensive interactions between RGB and depth channels for
RGB-D SOD. Specifically, three RGB-depth interaction modules, named CMW-L,
CMW-M and CMW-H, are developed to deal with respectively low-, middle- and
high-level cross-modal information fusion. These modules use Depth-to-RGB
Weighing (DW) and RGB-to-RGB Weighting (RW) to allow rich cross-modal and
cross-scale interactions among feature layers generated by different network
blocks. To effectively train the proposed Cross-Modal Weighting Network
(CMWNet), we design a composite loss function that summarizes the errors
between intermediate predictions and ground truth over different scales. With
all these novel components working together, CMWNet effectively fuses
information from RGB and depth channels, and meanwhile explores object
localization and details across scales. Thorough evaluations demonstrate CMWNet
consistently outperforms 15 state-of-the-art RGB-D SOD methods on seven popular
benchmarks.
\\ ( https://arxiv.org/abs/2007.04901 ,  4777kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04905
Date: Thu, 9 Jul 2020 16:05:37 GMT   (2484kb,D)

Title: Uncertainty Quantification in Deep Residual Neural Networks
Authors: Lukasz Wandzik, Raul Vicente Garcia, J\"org Kr\"uger
Categories: cs.CV
\\
  Uncertainty quantification is an important and challenging problem in deep
learning. Previous methods rely on dropout layers which are not present in
modern deep architectures or batch normalization which is sensitive to batch
sizes. In this work, we address the problem of uncertainty quantification in
deep residual networks by using a regularization technique called stochastic
depth. We show that training residual networks using stochastic depth can be
interpreted as a variational approximation to the intractable posterior over
the weights in Bayesian neural networks. We demonstrate that by sampling from a
distribution of residual networks with varying depth and shared weights,
meaningful uncertainty estimates can be obtained. Moreover, compared to the
original formulation of residual networks, our method produces well-calibrated
softmax probabilities with only minor changes to the network's structure. We
evaluate our approach on popular computer vision datasets and measure the
quality of uncertainty estimates. We also test the robustness to domain shift
and show that our method is able to express higher predictive uncertainty on
out-of-distribution samples. Finally, we demonstrate how the proposed approach
could be used to obtain uncertainty estimates in facial verification
applications.
\\ ( https://arxiv.org/abs/2007.04905 ,  2484kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04928
Date: Thu, 9 Jul 2020 17:01:08 GMT   (8126kb,D)

Title: Patient-Specific Domain Adaptation for Fast Optical Flow Based on
  Teacher-Student Knowledge Transfer
Authors: Sontje Ihler and Max-Heinrich Laves and Tobias Ortmaier
Categories: cs.CV
\\
  Fast motion feedback is crucial in computer-aided surgery (CAS) on moving
tissue. Image-assistance in safety-critical vision applications requires a
dense tracking of tissue motion. This can be done using optical flow (OF).
Accurate motion predictions at high processing rates lead to higher patient
safety. Current deep learning OF models show the common speed vs. accuracy
trade-off. To achieve high accuracy at high processing rates, we propose
patient-specific fine-tuning of a fast model. This minimizes the domain gap
between training and application data, while reducing the target domain to the
capability of the lower complex, fast model. We propose to obtain training
sequences pre-operatively in the operation room. We handle missing ground
truth, by employing teacher-student learning. Using flow estimations from
teacher model FlowNet2 we specialize a fast student model FlowNet2S on the
patient-specific domain. Evaluation is performed on sequences from the Hamlyn
dataset. Our student model shows very good performance after fine-tuning.
Tracking accuracy is comparable to the teacher model at a speed up of factor
six. Fine-tuning can be performed within minutes, making it feasible for the
operation room. Our method allows to use a real-time capable model that was
previously not suited for this task. This method is laying the path for
improved patient-specific motion estimation in CAS.
\\ ( https://arxiv.org/abs/2007.04928 ,  8126kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04931
Date: Thu, 9 Jul 2020 17:02:09 GMT   (1821kb,D)

Title: Single architecture and multiple task deep neural network for altered
  fingerprint analysis
Authors: Oliver Giudice (1), Mattia Litrico (1), Sebastiano Battiato (1 and 2)
  ((1) University of Catania, (2) iCTLab s.r.l. - Spin-off of University of
  Catania)
Categories: cs.CV
\\
  Fingerprints are one of the most copious evidence in a crime scene and, for
this reason, they are frequently used by law enforcement for identification of
individuals. But fingerprints can be altered. "Altered fingerprints", refers to
intentionally damage of the friction ridge pattern and they are often used by
smart criminals in hope to evade law enforcement. We use a deep neural network
approach training an Inception-v3 architecture. This paper proposes a method
for detection of altered fingerprints, identification of types of alterations
and recognition of gender, hand and fingers. We also produce activation maps
that show which part of a fingerprint the neural network has focused on, in
order to detect where alterations are positioned. The proposed approach
achieves an accuracy of 98.21%, 98.46%, 92.52%, 97.53% and 92,18% for the
classification of fakeness, alterations, gender, hand and fingers, respectively
on the SO.CO.FING. dataset.
\\ ( https://arxiv.org/abs/2007.04931 ,  1821kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04934
Date: Thu, 9 Jul 2020 17:05:32 GMT   (5815kb,D)

Title: Anyone here? Smart embedded low-resolution omnidirectional video sensor
  to measure room occupancy
Authors: Timothy Callemein, Kristof Van Beeck and Toon Goedem\'e
Categories: cs.CV
DOI: 10.1109/ICMLA.2019.00319
\\
  In this paper, we present a room occupancy sensing solution with unique
properties: (i) It is based on an omnidirectional vision camera, capturing rich
scene info over a wide angle, enabling to count the number of people in a room
and even their position. (ii) Although it uses a camera-input, no privacy
issues arise because its extremely low image resolution, rendering people
unrecognisable. (iii) The neural network inference is running entirely on a
low-cost processing platform embedded in the sensor, reducing the privacy risk
even further. (iv) Limited manual data annotation is needed, because of the
self-training scheme we propose. Such a smart room occupancy rate sensor can be
used in e.g. meeting rooms and flex-desks. Indeed, by encouraging flex-desking,
the required office space can be reduced significantly. In some cases, however,
a flex-desk that has been reserved remains unoccupied without an update in the
reservation system. A similar problem occurs with meeting rooms, which are
often under-occupied. By optimising the occupancy rate a huge reduction in
costs can be achieved. Therefore, in this paper, we develop such system which
determines the number of people present in office flex-desks and meeting rooms.
Using an omnidirectional camera mounted in the ceiling, combined with a person
detector, the company can intelligently update the reservation system based on
the measured occupancy. Next to the optimisation and embedded implementation of
such a self-training omnidirectional people detection algorithm, in this work
we propose a novel approach that combines spatial and temporal image data,
improving performance of our system on extreme low-resolution images.
\\ ( https://arxiv.org/abs/2007.04934 ,  5815kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04940
Date: Thu, 9 Jul 2020 17:10:11 GMT   (6147kb,D)

Title: The Phong Surface: Efficient 3D Model Fitting using Lifted Optimization
Authors: Jingjing Shen, Thomas J. Cashman, Qi Ye, Tim Hutton, Toby Sharp,
  Federica Bogo, Andrew William Fitzgibbon, Jamie Shotton
Categories: cs.CV
Journal-ref: ECCV2020
\\
  Realtime perceptual and interaction capabilities in mixed reality require a
range of 3D tracking problems to be solved at low latency on
resource-constrained hardware such as head-mounted devices. Indeed, for devices
such as HoloLens 2 where the CPU and GPU are left available for applications,
multiple tracking subsystems are required to run on a continuous, real-time
basis while sharing a single Digital Signal Processor. To solve model-fitting
problems for HoloLens 2 hand tracking, where the computational budget is
approximately 100 times smaller than an iPhone 7, we introduce a new surface
model: the `Phong surface'. Using ideas from computer graphics, the Phong
surface describes the same 3D shape as a triangulated mesh model, but with
continuous surface normals which enable the use of lifting-based optimization,
providing significant efficiency gains over ICP-based methods. We show that
Phong surfaces retain the convergence benefits of smoother surface models,
while triangle meshes do not.
\\ ( https://arxiv.org/abs/2007.04940 ,  6147kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04942
Date: Thu, 9 Jul 2020 17:14:15 GMT   (1799kb,D)

Title: Real-time Embedded Person Detection and Tracking for Shopping Behaviour
  Analysis
Authors: Robin Schrijvers, Steven Puttemans, Timothy Callemein and Toon
  Goedem\'e
Categories: cs.CV
DOI: 10.1007/978-3-030-40605-9_46
\\
  Shopping behaviour analysis through counting and tracking of people in
shop-like environments offers valuable information for store operators and
provides key insights in the stores layout (e.g. frequently visited spots).
Instead of using extra staff for this, automated on-premise solutions are
preferred. These automated systems should be cost-effective, preferably on
lightweight embedded hardware, work in very challenging situations (e.g.
handling occlusions) and preferably work real-time. We solve this challenge by
implementing a real-time TensorRT optimized YOLOv3-based pedestrian detector,
on a Jetson TX2 hardware platform. By combining the detector with a sparse
optical flow tracker we assign a unique ID to each customer and tackle the
problem of loosing partially occluded customers. Our detector-tracker based
solution achieves an average precision of 81.59% at a processing speed of 10
FPS. Besides valuable statistics, heat maps of frequently visited spots are
extracted and used as an overlay on the video stream.
\\ ( https://arxiv.org/abs/2007.04942 ,  1799kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04950
Date: Thu, 9 Jul 2020 17:24:40 GMT   (2860kb,D)

Title: AI Assisted Apparel Design
Authors: Alpana Dubey, Nitish Bhardwaj, Kumar Abhinav, Suma Mani Kuriakose,
  Sakshi Jain and Veenu Arora
Categories: cs.CV cs.AI cs.HC
\\
  Fashion is a fast-changing industry where designs are refreshed at large
scale every season. Moreover, it faces huge challenge of unsold inventory as
not all designs appeal to customers. This puts designers under significant
pressure. Firstly, they need to create innumerous fresh designs. Secondly, they
need to create designs that appeal to customers. Although we see advancements
in approaches to help designers analyzing consumers, often such insights are
too many. Creating all possible designs with those insights is time consuming.
In this paper, we propose a system of AI assistants that assists designers in
their design journey. The proposed system assists designers in analyzing
different selling/trending attributes of apparels. We propose two design
generation assistants namely Apparel-Style-Merge and Apparel-Style-Transfer.
Apparel-Style-Merge generates new designs by combining high level components of
apparels whereas Apparel-Style-Transfer generates multiple customization of
apparels by applying different styles, colors and patterns. We compose a new
dataset, named DeepAttributeStyle, with fine-grained annotation of landmarks of
different apparel components such as neck, sleeve etc. The proposed system is
evaluated on a user group consisting of people with and without design
background. Our evaluation result demonstrates that our approach generates high
quality designs that can be easily used in fabrication. Moreover, the suggested
designs aid to the designers creativity.
\\ ( https://arxiv.org/abs/2007.04950 ,  2860kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04954
Date: Thu, 9 Jul 2020 17:33:27 GMT   (6207kb,D)

Title: ThreeDWorld: A Platform for Interactive Multi-Modal Physical Simulation
Authors: Chuang Gan, Jeremy Schwartz, Seth Alter, Martin Schrimpf, James Traer,
  Julian De Freitas, Jonas Kubilius, Abhishek Bhandwaldar, Nick Haber, Megumi
  Sano, Kuno Kim, Elias Wang, Damian Mrowca, Michael Lingelbach, Aidan Curtis,
  Kevin Feigelis, Daniel M. Bear, Dan Gutfreund, David Cox, James J. DiCarlo,
  Josh McDermott, Joshua B. Tenenbaum, Daniel L.K. Yamins
Categories: cs.CV cs.GR cs.LG cs.RO
Comments: Project page: http://www.threedworld.org
\\
  We introduce ThreeDWorld (TDW), a platform for interactive multi-modal
physical simulation. With TDW, users can simulate high-fidelity sensory data
and physical interactions between mobile agents and objects in a wide variety
of rich 3D environments. TDW has several unique properties: 1) realtime near
photo-realistic image rendering quality; 2) a library of objects and
environments with materials for high-quality rendering, and routines enabling
user customization of the asset library; 3) generative procedures for
efficiently building classes of new environments 4) high-fidelity audio
rendering; 5) believable and realistic physical interactions for a wide variety
of material types, including cloths, liquid, and deformable objects; 6) a range
of "avatar" types that serve as embodiments of AI agents, with the option for
user avatar customization; and 7) support for human interactions with VR
devices. TDW also provides a rich API enabling multiple agents to interact
within a simulation and return a range of sensor and physics data representing
the state of the world. We present initial experiments enabled by the platform
around emerging research directions in computer vision, machine learning, and
cognitive science, including multi-modal physical scene understanding,
multi-agent interactions, models that "learn like a child", and attention
studies in humans and neural networks. The simulation platform will be made
publicly available.
\\ ( https://arxiv.org/abs/2007.04954 ,  6207kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04964
Date: Thu, 9 Jul 2020 17:51:56 GMT   (658kb,D)

Title: Improving Style-Content Disentanglement in Image-to-Image Translation
Authors: Aviv Gabbay and Yedid Hoshen
Categories: cs.CV cs.LG
Comments: Project page:
  http://www.vision.huji.ac.il/style-content-disentanglement
\\
  Unsupervised image-to-image translation methods have achieved tremendous
success in recent years. However, it can be easily observed that their models
contain significant entanglement which often hurts the translation performance.
In this work, we propose a principled approach for improving style-content
disentanglement in image-to-image translation. By considering the information
flow into each of the representations, we introduce an additional loss term
which serves as a content-bottleneck. We show that the results of our method
are significantly more disentangled than those produced by current methods,
while further improving the visual quality and translation diversity.
\\ ( https://arxiv.org/abs/2007.04964 ,  658kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04978
Date: Thu, 9 Jul 2020 17:59:54 GMT   (2058kb,D)

Title: Novel Subtypes of Pulmonary Emphysema Based on Spatially-Informed Lung
  Texture Learning
Authors: Jie Yang, Elsa D. Angelini, Pallavi P. Balte, Eric A. Hoffman, John
  H.M. Austin, Benjamin M. Smith, R. Graham Barr, and Andrew F. Laine
Categories: cs.CV cs.LG
\\
  Pulmonary emphysema overlaps considerably with chronic obstructive pulmonary
disease (COPD), and is traditionally subcategorized into three subtypes
previously identified on autopsy. Unsupervised learning of emphysema subtypes
on computed tomography (CT) opens the way to new definitions of emphysema
subtypes and eliminates the need of thorough manual labeling. However, CT-based
emphysema subtypes have been limited to texture-based patterns without
considering spatial location. In this work, we introduce a standardized spatial
mapping of the lung for quantitative study of lung texture location, and
propose a novel framework for combining spatial and texture information to
discover spatially-informed lung texture patterns (sLTPs) that represent novel
emphysema subtypes. Exploiting two cohorts of full-lung CT scans from the MESA
COPD and EMCAP studies, we first show that our spatial mapping enables
population-wide study of emphysema spatial location. We then evaluate the
characteristics of the sLTPs discovered on MESA COPD, and show that they are
reproducible, able to encode standard emphysema subtypes, and associated with
physiological symptoms.
\\ ( https://arxiv.org/abs/2007.04978 ,  2058kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04979
Date: Thu, 9 Jul 2020 17:59:57 GMT   (7165kb,D)

Title: A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied
  Tasks
Authors: Unnat Jain, Luca Weihs, Eric Kolve, Ali Farhadi, Svetlana Lazebnik,
  Aniruddha Kembhavi, Alexander Schwing
Categories: cs.CV cs.AI cs.LG cs.MA
Comments: Accepted to ECCV 2020 (spotlight); Project page:
  https://unnat.github.io/cordial-sync
\\
  Autonomous agents must learn to collaborate. It is not scalable to develop a
new centralized agent every time a task's difficulty outpaces a single agent's
abilities. While multi-agent collaboration research has flourished in
gridworld-like environments, relatively little work has considered visually
rich domains. Addressing this, we introduce the novel task FurnMove in which
agents work together to move a piece of furniture through a living room to a
goal. Unlike existing tasks, FurnMove requires agents to coordinate at every
timestep. We identify two challenges when training agents to complete FurnMove:
existing decentralized action sampling procedures do not permit expressive
joint action policies and, in tasks requiring close coordination, the number of
failed actions dominates successful actions. To confront these challenges we
introduce SYNC-policies (synchronize your actions coherently) and CORDIAL
(coordination loss). Using SYNC-policies and CORDIAL, our agents achieve a 58%
completion rate on FurnMove, an impressive absolute gain of 25 percentage
points over competitive decentralized baselines. Our dataset, code, and
pretrained models are available at https://unnat.github.io/cordial-sync .
\\ ( https://arxiv.org/abs/2007.04979 ,  7165kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04698
Date: Thu, 9 Jul 2020 10:45:18 GMT   (17kb,D)

Title: Cycle Extendability of Hamiltonian Strongly Chordal Graphs
Authors: Guozhen Rong, Wenjun Li, Jianxin Wang, Yongjie Yang
Categories: cs.DM math.CO
Comments: 14 pages, 5 figures
\\
  In 1990, Hendry conjectured that all Hamiltonian chordal graphs are cycle
extendable. After a series of papers confirming the conjecture for a number of
graph classes, the conjecture is yet refuted by Lafond and Seamone in 2015.
Given that their counterexamples are not strongly chordal graphs and they are
all only $2$-connected, Lafond and Seamone asked the following two questions:
(1) Are Hamiltonian strongly chordal graphs cycle extendable? (2) Is there an
integer $k$ such that all $k$-connected Hamiltonian chordal graphs are cycle
extendable? Later, a conjecture stronger than Hendry's is proposed. In this
paper, we resolve all these questions in the negative. On the positive side, we
add to the list of cycle extendable graphs two more graph classes, namely,
Hamiltonian $4$-leaf powers and Hamiltonian {4-FAN, $\overline{A}$}-free
chordal graphs.
\\ ( https://arxiv.org/abs/2007.04698 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04464
Date: Wed, 8 Jul 2020 22:45:15 GMT   (3752kb,D)

Title: Deform, Cut and Tear a skinned model using Conformal Geometric Algebra
Authors: Manos Kamarianakis and George Papagiannakis
Categories: cs.GR
Comments: 13 Pages, 4 figures, accepted in CGI 2020 conference (ENGAGE
  workshop), will appear in Springer LNCS proceedings
MSC-class: 68U05
ACM-class: I.3.8
\\
  In this work, we present a novel, integrated rigged character simulation
framework in Conformal Geometric Algebra (CGA) that supports, for the first
time, real-time cuts and tears, before and/or after the animation, while
maintaining deformation topology. The purpose of using CGA is to lift several
restrictions posed by current state-of-the-art character animation &
deformation methods. Previous implementations originally required weighted
matrices to perform deformations, whereas, in the current state-of-the-art,
dual-quaternions handle both rotations and translations, but cannot handle
dilations. CGA is a suitable extension of dual-quaternion algebra that amends
these two major previous shortcomings: the need to constantly transmute between
matrices and dual-quaternions as well as the inability to properly dilate a
model during animation. Our CGA algorithm also provides easy interpolation and
application of all deformations in each intermediate steps, all within the same
geometric framework. Furthermore we also present two novel algorithms that
enable cutting and tearing of the input rigged, animated model, while the
output model can be further re-deformed. These interactive, real-time cut and
tear operations can enable a new suite of applications, especially under the
scope of a medical surgical simulation.
\\ ( https://arxiv.org/abs/2007.04464 ,  3752kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2007.04842 (*cross-listing*)
Date: Thu, 9 Jul 2020 14:44:19 GMT   (4919kb,D)

Title: An Interior Point Method Solving Motion Planning Problems with Narrow
  Passages
Authors: Jim Mainprice and Nathan Ratliff and Marc Toussaint and Stefan Schaal
Categories: cs.RO cs.CG
Comments: IEEE RO-MAN 2020, 6 pages
\\
  Algorithmic solutions for the motion planning problem have been investigated
for five decades. Since the development of A* in 1969 many approaches have been
investigated, traditionally classified as either grid decomposition, potential
fields or sampling-based. In this work, we focus on using numerical
optimization, which is understudied for solving motion planning problems. This
lack of interest in the favor of sampling-based methods is largely due to the
non-convexity introduced by narrow passages. We address this shortcoming by
grounding the motion planning problem in differential geometry. We demonstrate
through a series of experiments on 3 Dofs and 6 Dofs narrow passage problems,
how modeling explicitly the underlying Riemannian manifold leads to an
efficient interior-point non-linear programming solution.
\\ ( https://arxiv.org/abs/2007.04842 ,  4919kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04344 (*cross-listing*)
Date: Wed, 8 Jul 2020 18:03:40 GMT   (567kb,D)

Title: Lightweight Image Super-Resolution with Enhanced CNN
Authors: Chunwei Tian, Ruibin Zhuge, Zhihao Wu, Yong Xu, Wangmeng Zuo, Chen
  Chen, Chia-Wen Li
Categories: eess.IV cs.CV
\\
  Deep convolutional neural networks (CNNs) with strong expressive ability have
achieved impressive performances on single image super-resolution (SISR).
However, their excessive amounts of convolutions and parameters usually consume
high computational cost and more memory storage for training a SR model, which
limits their applications to SR with resource-constrained devices in real
world. To resolve these problems, we propose a lightweight enhanced SR CNN
(LESRCN-N) with three successive sub-blocks, an information extraction and
enhancement block (IEEB), a reconstruction block (RB) and an information
refinement block (IRB). Specifically, the IEEB extracts hierarchical
low-resolution (LR) features and aggregates the obtained features step-by-step
to increase the memory ability of the shallow layers on deep layers for SISR.
To remove redundant information obtained, a heterogeneous architecture is
adopted in the IEEB. After that, the RB converts low-frequency features into
high-frequency features by fusing global and local features, which is
complementary with the IEEB in tackling the long-term dependency problem.
Finally, the IRB uses coarse high-frequency features from the RB to learn more
accurate SR features and construct a SR image. The proposed LESRCNN can obtain
a high-quality image by a model for different scales. Extensive experiments
demonstrate that the proposed LESRCNN outperforms state-of-the-arts on SISR in
terms of qualitative and quantitative evaluation.
\\ ( https://arxiv.org/abs/2007.04344 ,  567kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04356 (*cross-listing*)
Date: Wed, 8 Jul 2020 18:24:40 GMT   (4289kb,D)

Title: Journey Towards Tiny Perceptual Super-Resolution
Authors: Royson Lee, {\L}ukasz Dudziak, Mohamed Abdelfattah, Stylianos I.
  Venieris, Hyeji Kim, Hongkai Wen, Nicholas D. Lane
Categories: eess.IV cs.CV
Comments: Accepted at the 16th European Conference on Computer Vision (ECCV),
  2020
\\
  Recent works in single-image perceptual super-resolution (SR) have
demonstrated unprecedented performance in generating realistic textures by
means of deep convolutional networks. However, these convolutional models are
excessively large and expensive, hindering their effective deployment to end
devices. In this work, we propose a neural architecture search (NAS) approach
that integrates NAS and generative adversarial networks (GANs) with recent
advances in perceptual SR and pushes the efficiency of small perceptual SR
models to facilitate on-device execution. Specifically, we search over the
architectures of both the generator and the discriminator sequentially,
highlighting the unique challenges and key observations of searching for an
SR-optimized discriminator and comparing them with existing discriminator
architectures in the literature. Our tiny perceptual SR (TPSR) models
outperform SRGAN and EnhanceNet on both full-reference perceptual metric
(LPIPS) and distortion metric (PSNR) while being up to 26.4$\times$ more memory
efficient and 33.6$\times$ more compute efficient respectively.
\\ ( https://arxiv.org/abs/2007.04356 ,  4289kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04480 (*cross-listing*)
Date: Wed, 8 Jul 2020 23:58:41 GMT   (436kb,D)

Title: Automatic Probe Movement Guidance for Freehand Obstetric Ultrasound
Authors: Richard Droste, Lior Drukker, Aris T. Papageorghiou, J. Alison Noble
Categories: eess.IV cs.CV cs.LG stat.ML
Comments: Accepted at the 23rd International Conference on Medical Image
  Computing and Computer Assisted Intervention (MICCAI 2020)
\\
  We present the first system that provides real-time probe movement guidance
for acquiring standard planes in routine freehand obstetric ultrasound
scanning. Such a system can contribute to the worldwide deployment of obstetric
ultrasound scanning by lowering the required level of operator expertise. The
system employs an artificial neural network that receives the ultrasound video
signal and the motion signal of an inertial measurement unit (IMU) that is
attached to the probe, and predicts a guidance signal. The network termed
US-GuideNet predicts either the movement towards the standard plane position
(goal prediction), or the next movement that an expert sonographer would
perform (action prediction). While existing models for other ultrasound
applications are trained with simulations or phantoms, we train our model with
real-world ultrasound video and probe motion data from 464 routine clinical
scans by 17 accredited sonographers. Evaluations for 3 standard plane types
show that the model provides a useful guidance signal with an accuracy of 88.8%
for goal prediction and 90.9% for action prediction.
\\ ( https://arxiv.org/abs/2007.04480 ,  436kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04546 (*cross-listing*)
Date: Thu, 9 Jul 2020 04:05:04 GMT   (4447kb,D)

Title: Wandering Within a World: Online Contextualized Few-Shot Learning
Authors: Mengye Ren, Michael L. Iuzzolino, Michael C. Mozer, Richard S. Zemel
Categories: cs.LG cs.CV stat.ML
\\
  We aim to bridge the gap between typical human and machine-learning
environments by extending the standard framework of few-shot learning to an
online, continual setting. In this setting, episodes do not have separate
training and testing phases, and instead models are evaluated online while
learning novel classes. As in real world, where the presence of spatiotemporal
context helps us retrieve learned skills in the past, our online few-shot
learning setting also features an underlying context that changes throughout
time. Object classes are correlated within a context and inferring the correct
context can lead to better performance. Building upon this setting, we propose
a new few-shot learning dataset based on large scale indoor imagery that mimics
the visual experience of an agent wandering within a world. Furthermore, we
convert popular few-shot learning approaches into online versions and we also
propose a new model named contextual prototypical memory that can make use of
spatiotemporal contextual information from the recent past.
\\ ( https://arxiv.org/abs/2007.04546 ,  4447kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04564 (*cross-listing*)
Date: Thu, 9 Jul 2020 05:35:49 GMT   (2631kb,D)

Title: Efficient detection of adversarial images
Authors: Darpan Kumar Yadav, Kartik Mundra, Rahul Modpur, Arpan Chattopadhyay
  and Indra Narayan Kar
Categories: eess.IV cs.CV cs.LG
Comments: 10 pages, 3 figures, 3 algorithms, 8 tables. Extension of the
  Conference paper:- Kartik Mundra, Rahul Modpur, Arpan Chattopadhyay, and
  Indra Narayan Kar. Adversarial image detection in cyber-physical systems. In
  Proceedings of the 1st ACM Workshop on Autonomous and Intelligent Mobile
  Systems, pages 1-5, 2020. Can be found at
  https://dl.acm.org/doi/abs/10.1145/3377283.3377285
\\
  In this paper, detection of deception attack on deep neural network (DNN)
based image classification in autonomous and cyber-physical systems is
considered. Several studies have shown the vulnerability of DNN to malicious
deception attacks. In such attacks, some or all pixel values of an image are
modified by an external attacker, so that the change is almost invisible to the
human eye but significant enough for a DNN-based classifier to misclassify it.
This paper first proposes a novel pre-processing technique that facilitates the
detection of such modified images under any DNN-based image classifier as well
as the attacker model. The proposed pre-processing algorithm involves a certain
combination of principal component analysis (PCA)-based decomposition of the
image, and random perturbation based detection to reduce computational
complexity. Next, an adaptive version of this algorithm is proposed where a
random number of perturbations are chosen adaptively using a doubly-threshold
policy, and the threshold values are learnt via stochastic approximation in
order to minimize the expected number of perturbations subject to constraints
on the false alarm and missed detection probabilities. Numerical experiments
show that the proposed detection scheme outperforms a competing algorithm while
achieving reasonably low computational complexity.
\\ ( https://arxiv.org/abs/2007.04564 ,  2631kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04574 (*cross-listing*)
Date: Thu, 9 Jul 2020 06:15:17 GMT   (8744kb,D)

Title: Neural Video Coding using Multiscale Motion Compensation and
  Spatiotemporal Context Model
Authors: Haojie Liu, Ming Lu, Zhan Ma, Fan Wang, Zhihuang Xie, Xun Cao, Yao
  Wang
Categories: eess.IV cs.CV
\\
  Over the past two decades, traditional block-based video coding has made
remarkable progress and spawned a series of well-known standards such as
MPEG-4, H.264/AVC and H.265/HEVC. On the other hand, deep neural networks
(DNNs) have shown their powerful capacity for visual content understanding,
feature extraction and compact representation. Some previous works have
explored the learnt video coding algorithms in an end-to-end manner, which show
the great potential compared with traditional methods. In this paper, we
propose an end-to-end deep neural video coding framework (NVC), which uses
variational autoencoders (VAEs) with joint spatial and temporal prior
aggregation (PA) to exploit the correlations in intra-frame pixels, inter-frame
motions and inter-frame compensation residuals, respectively. Novel features of
NVC include: 1) To estimate and compensate motion over a large range of
magnitudes, we propose an unsupervised multiscale motion compensation network
(MS-MCN) together with a pyramid decoder in the VAE for coding motion features
that generates multiscale flow fields, 2) we design a novel adaptive
spatiotemporal context model for efficient entropy coding for motion
information, 3) we adopt nonlocal attention modules (NLAM) at the bottlenecks
of the VAEs for implicit adaptive feature extraction and activation, leveraging
its high transformation capacity and unequal weighting with joint global and
local information, and 4) we introduce multi-module optimization and a
multi-frame training strategy to minimize the temporal error propagation among
P-frames. NVC is evaluated for the low-delay causal settings and compared with
H.265/HEVC, H.264/AVC and the other learnt video compression methods following
the common test conditions, demonstrating consistent gains across all popular
test sequences for both PSNR and MS-SSIM distortion metrics.
\\ ( https://arxiv.org/abs/2007.04574 ,  8744kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04589 (*cross-listing*)
Date: Thu, 9 Jul 2020 06:56:11 GMT   (8605kb,D)

Title: InfoMax-GAN: Improved Adversarial Image Generation via Information
  Maximization and Contrastive Learning
Authors: Kwot Sin Lee, Ngoc-Trung Tran, Ngai-Man Cheung
Categories: cs.LG cs.CV stat.ML
Comments: Initial version was presented at NeurIPS 2019 Workshop on Information
  Theory and Machine Learning
\\
  While Generative Adversarial Networks (GANs) are fundamental to many
generative modelling applications, they suffer from numerous issues. In this
work, we propose a principled framework to simultaneously address two
fundamental issues in GANs: catastrophic forgetting of the discriminator and
mode collapse of the generator. We achieve this by employing for GANs a
contrastive learning and mutual information maximization approach, and perform
extensive analyses to understand sources of improvements. Our approach
significantly stabilises GAN training and improves GAN performance for image
synthesis across five datasets under the same training and evaluation
conditions against state-of-the-art works. Our approach is simple to implement
and practical: it involves only one objective, is computationally inexpensive,
and is robust across a wide range of hyperparameters without any tuning. For
reproducibility, our code is available at https://github.com/kwotsin/mimicry.
\\ ( https://arxiv.org/abs/2007.04589 ,  8605kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04645 (*cross-listing*)
Date: Thu, 9 Jul 2020 08:56:53 GMT   (2376kb,D)

Title: Learning to Switch CNNs with Model Agnostic Meta Learning for Fine
  Precision Visual Servoing
Authors: Prem Raj, Vinay P. Namboodiri and L. Behera
Categories: cs.RO cs.CV
Comments: Accepted in IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS-2020). For video visit - https://youtu.be/GSG20lmWDUo
\\
  Convolutional Neural Networks (CNNs) have been successfully applied for
relative camera pose estimation from labeled image-pair data, without requiring
any hand-engineered features, camera intrinsic parameters or depth information.
The trained CNN can be utilized for performing pose based visual servo control
(PBVS). One of the ways to improve the quality of visual servo output is to
improve the accuracy of the CNN for estimating the relative pose estimation.
With a given state-of-the-art CNN for relative pose regression, how can we
achieve an improved performance for visual servo control? In this paper, we
explore switching of CNNs to improve the precision of visual servo control. The
idea of switching a CNN is due to the fact that the dataset for training a
relative camera pose regressor for visual servo control must contain variations
in relative pose ranging from a very small scale to eventually a larger scale.
We found that, training two different instances of the CNN, one for
large-scale-displacements (LSD) and another for small-scale-displacements (SSD)
and switching them during the visual servo execution yields better results than
training a single CNN with the combined LSD+SSD data. However, it causes extra
storage overhead and switching decision is taken by a manually set threshold
which may not be optimal for all the scenes. To eliminate these drawbacks, we
propose an efficient switching strategy based on model agnostic meta learning
(MAML) algorithm. In this, a single model is trained to learn parameters which
are simultaneously good for multiple tasks, namely a binary classification for
switching decision, a 6DOF pose regression for LSD data and also a 6DOF pose
regression for SSD data. The proposed approach performs far better than the
naive approach, while storage and run-time overheads are almost negligible.
\\ ( https://arxiv.org/abs/2007.04645 ,  2376kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04670 (*cross-listing*)
Date: Thu, 9 Jul 2020 09:54:05 GMT   (937kb,D)

Title: Multi-Granularity Modularized Network for Abstract Visual Reasoning
Authors: Xiangru Tang, Haoyuan Wang, Xiang Pan, Jiyang Qi
Categories: cs.AI cs.CV
\\
  Abstract visual reasoning connects mental abilities to the physical world,
which is a crucial factor in cognitive development. Most toddlers display
sensitivity to this skill, but it is not easy for machines. Aimed at it, we
focus on the Raven Progressive Matrices Test, designed to measure cognitive
reasoning. Recent work designed some black-boxes to solve it in an end-to-end
fashion, but they are incredibly complicated and difficult to explain. Inspired
by cognitive studies, we propose a Multi-Granularity Modularized Network (MMoN)
to bridge the gap between the processing of raw sensory information and
symbolic reasoning. Specifically, it learns modularized reasoning functions to
model the semantic rule from the visual grounding in a neuro-symbolic and
semi-supervision way. To comprehensively evaluate MMoN, our experiments are
conducted on the dataset of both seen and unseen reasoning rules. The result
shows that MMoN is well suited for abstract visual reasoning and also
explainable on the generalization test.
\\ ( https://arxiv.org/abs/2007.04670 ,  937kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04734 (*cross-listing*)
Date: Thu, 9 Jul 2020 12:12:16 GMT   (1419kb,D)

Title: Brain Tumor Anomaly Detection via Latent Regularized Adversarial Network
Authors: Nan Wang, Chengwei Chen, Yuan Xie, Lizhuang Ma
Categories: eess.IV cs.CV
Comments: 9 pages, 7 figures
MSC-class: 68T07
ACM-class: I.4.9
\\
  With the development of medical imaging technology, medical images have
become an important basis for doctors to diagnose patients. The brain structure
in the collected data is complicated, thence, doctors are required to spend
plentiful energy when diagnosing brain abnormalities. Aiming at the imbalance
of brain tumor data and the rare amount of labeled data, we propose an
innovative brain tumor abnormality detection algorithm. The semi-supervised
anomaly detection model is proposed in which only healthy (normal) brain images
are trained. Model capture the common pattern of the normal images in the
training process and detect anomalies based on the reconstruction error of
latent space. Furthermore, the method first uses singular value to constrain
the latent space and jointly optimizes the image space through multiple loss
functions, which make normal samples and abnormal samples more separable in the
feature-level. This paper utilizes BraTS, HCP, MNIST, and CIFAR-10 datasets to
comprehensively evaluate the effectiveness and practicability. Extensive
experiments on intra- and cross-dataset tests prove that our semi-supervised
method achieves outperforms or comparable results to state-of-the-art
supervised techniques.
\\ ( https://arxiv.org/abs/2007.04734 ,  1419kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04754 (*cross-listing*)
Date: Thu, 9 Jul 2020 12:59:28 GMT   (1901kb,D)

Title: JBFnet -- Low Dose CT Denoising by Trainable Joint Bilateral Filtering
Authors: Mayank Patwari, Ralf Gutjahr, Rainer Raupach, Andreas Maier
Categories: eess.IV cs.CV cs.LG
Comments: 10 pages, 4 figures, 1 table. Accepted at MICCAI2020
\\
  Deep neural networks have shown great success in low dose CT denoising.
However, most of these deep neural networks have several hundred thousand
trainable parameters. This, combined with the inherent non-linearity of the
neural network, makes the deep neural network diffcult to understand with low
accountability. In this study we introduce JBFnet, a neural network for low
dose CT denoising. The architecture of JBFnet implements iterative bilateral
filtering. The filter functions of the Joint Bilateral Filter (JBF) are learned
via shallow convolutional networks. The guidance image is estimated by a deep
neural network. JBFnet is split into four filtering blocks, each of which
performs Joint Bilateral Filtering. Each JBF block consists of 112 trainable
parameters, making the noise removal process comprehendable. The Noise Map (NM)
is added after filtering to preserve high level features. We train JBFnet with
the data from the body scans of 10 patients, and test it on the AAPM low dose
CT Grand Challenge dataset. We compare JBFnet with state-of-the-art deep
learning networks. JBFnet outperforms CPCE3D, GAN and deep GFnet on the test
dataset in terms of noise removal while preserving structures. We conduct
several ablation studies to test the performance of our network architecture
and training method. Our current setup achieves the best performance, while
still maintaining behavioural accountability.
\\ ( https://arxiv.org/abs/2007.04754 ,  1901kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04768 (*cross-listing*)
Date: Thu, 9 Jul 2020 13:17:36 GMT   (740kb,D)

Title: Low Dose CT Denoising via Joint Bilateral Filtering and Intelligent
  Parameter Optimization
Authors: Mayank Patwari, Ralf Gutjahr, Rainer Raupach, Andreas Maier
Categories: eess.IV cs.CV cs.LG
Comments: 4 pages, 5 figures, 1 table. Accepted at CT Meeting 2020
\\
  Denoising of clinical CT images is an active area for deep learning research.
Current clinically approved methods use iterative reconstruction methods to
reduce the noise in CT images. Iterative reconstruction techniques require
multiple forward and backward projections, which are time-consuming and
computationally expensive. Recently, deep learning methods have been
successfully used to denoise CT images. However, conventional deep learning
methods suffer from the 'black box' problem. They have low accountability,
which is necessary for use in clinical imaging situations. In this paper, we
use a Joint Bilateral Filter (JBF) to denoise our CT images. The guidance image
of the JBF is estimated using a deep residual convolutional neural network
(CNN). The range smoothing and spatial smoothing parameters of the JBF are
tuned by a deep reinforcement learning task. Our actor first chooses a
parameter, and subsequently chooses an action to tune the value of the
parameter. A reward network is designed to direct the reinforcement learning
task. Our denoising method demonstrates good denoising performance, while
retaining structural information. Our method significantly outperforms state of
the art deep neural networks. Moreover, our method has only two parameters,
which makes it significantly more interpretable and reduces the 'black box'
problem. We experimentally measure the impact of our intelligent parameter
optimization and our reward network. Our studies show that our current setup
yields the best results in terms of structural preservation.
\\ ( https://arxiv.org/abs/2007.04768 ,  740kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04774 (*cross-listing*)
Date: Wed, 24 Jun 2020 17:29:26 GMT   (688kb)

Title: Automated Chest CT Image Segmentation of COVID-19 Lung Infection based
  on 3D U-Net
Authors: Dominik M\"uller, I\~naki Soto Rey, Frank Kramer
Categories: eess.IV cs.CV cs.LG
Comments: Code repository: https://github.com/frankkramer-lab/covid19.MIScnn
\\
  The coronavirus disease 2019 (COVID-19) affects billions of lives around the
world and has a significant impact on public healthcare. Due to rising
skepticism towards the sensitivity of RT-PCR as screening method, medical
imaging like computed tomography offers great potential as alternative. For
this reason, automated image segmentation is highly desired as clinical
decision support for quantitative assessment and disease monitoring. However,
publicly available COVID-19 imaging data is limited which leads to overfitting
of traditional approaches. To address this problem, we propose an innovative
automated segmentation pipeline for COVID-19 infected regions, which is able to
handle small datasets by utilization as variant databases. Our method focuses
on on-the-fly generation of unique and random image patches for training by
performing several preprocessing methods and exploiting extensive data
augmentation. For further reduction of the overfitting risk, we implemented a
standard 3D U-Net architecture instead of new or computational complex neural
network architectures. Through a 5-fold cross-validation on 20 CT scans of
COVID-19 patients, we were able to develop a highly accurate as well as robust
segmentation model for lungs and COVID-19 infected regions without overfitting
on the limited data. Our method achieved Dice similarity coefficients of 0.956
for lungs and 0.761 for infection. We demonstrated that the proposed method
outperforms related approaches, advances the state-of-the-art for COVID-19
segmentation and improves medical image analysis with limited data. The code
and model are available under the following link:
https://github.com/frankkramer-lab/covid19.MIScnn
\\ ( https://arxiv.org/abs/2007.04774 ,  688kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04780 (*cross-listing*)
Date: Thu, 9 Jul 2020 13:23:15 GMT   (2693kb,D)

Title: Modelling the Distribution of 3D Brain MRI using a 2D Slice VAE
Authors: Anna Volokitin, Ertunc Erdil, Neerav Karani, Kerem Can Tezcan, Xiaoran
  Chen, Luc Van Gool, Ender Konukoglu
Categories: eess.IV cs.CV
Comments: accepted for publication at MICCAI 2020. Code available
  https://github.com/voanna/slices-to-3d-brain-vae/
\\
  Probabilistic modelling has been an essential tool in medical image analysis,
especially for analyzing brain Magnetic Resonance Images (MRI). Recent deep
learning techniques for estimating high-dimensional distributions, in
particular Variational Autoencoders (VAEs), opened up new avenues for
probabilistic modeling. Modelling of volumetric data has remained a challenge,
however, because constraints on available computation and training data make it
difficult effectively leverage VAEs, which are well-developed for 2D images. We
propose a method to model 3D MR brain volumes distribution by combining a 2D
slice VAE with a Gaussian model that captures the relationships between slices.
We do so by estimating the sample mean and covariance in the latent space of
the 2D model over the slice direction. This combined model lets us sample new
coherent stacks of latent variables to decode into slices of a volume. We also
introduce a novel evaluation method for generated volumes that quantifies how
well their segmentations match those of true brain anatomy. We demonstrate that
our proposed model is competitive in generating high quality volumes at high
resolutions according to both traditional metrics and our proposed evaluation.
\\ ( https://arxiv.org/abs/2007.04780 ,  2693kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04782 (*cross-listing*)
Date: Thu, 9 Jul 2020 13:23:40 GMT   (1063kb)

Title: A Systematic Review on Context-Aware Recommender Systems using Deep
  Learning and Embeddings
Authors: Igor Andr\'e Pegoraro Santana, Marcos Aurelio Domingues
Categories: cs.IR cs.CV
Comments: 15 pages
\\
  Recommender Systems are tools that improve how users find relevant
information in web systems, so they do not face too much information. In order
to generate better recommendations, the context of information should be used
in the recommendation process. Context-Aware Recommender Systems were created,
accomplishing state-of-the-art results and improving traditional recommender
systems. There are many approaches to build recommender systems, and two of the
most prominent advances in area have been the use of Embeddings to represent
the data in the recommender system, and the use of Deep Learning architectures
to generate the recommendations to the user. A systematic review adopts a
formal and systematic method to perform a bibliographic review, and it is used
to identify and evaluate all the research in certain area of study, by
analyzing the relevant research published. A systematic review was conducted to
understand how the Deep Learning and Embeddings techniques are being applied to
improve Context-Aware Recommender Systems. We summarized the architectures that
are used to create those and the domains that they are used.
\\ ( https://arxiv.org/abs/2007.04782 ,  1063kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04806 (*cross-listing*)
Date: Thu, 9 Jul 2020 13:48:39 GMT   (1907kb,D)

Title: Client Adaptation improves Federated Learning with Simulated Non-IID
  Clients
Authors: Laura Rieger, Rasmus M. Th. H{\o}egh, and Lars K. Hansen
Categories: cs.LG cs.CV stat.ML
Comments: 11 pages, 11 figures. To appear at International Workshop on
  Federated Learning for User Privacy and Data Confidentiality in Conjunction
  with ICML 2020
\\
  We present a federated learning approach for learning a client adaptable,
robust model when data is non-identically and non-independently distributed
(non-IID) across clients. By simulating heterogeneous clients, we show that
adding learned client-specific conditioning improves model performance, and the
approach is shown to work on balanced and imbalanced data set from both audio
and image domains. The client adaptation is implemented by a conditional gated
activation unit and is particularly beneficial when there are large differences
between the data distribution for each client, a common scenario in federated
learning.
\\ ( https://arxiv.org/abs/2007.04806 ,  1907kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04807 (*cross-listing*)
Date: Thu, 9 Jul 2020 13:50:18 GMT   (3877kb,D)

Title: Medical Instrument Detection in Ultrasound-Guided Interventions: A
  Review
Authors: Hongxu Yang, Caifeng Shan, Alexander F. Kolen, Peter H. N. de With
Categories: eess.IV cs.CV physics.med-ph
Comments: Draft paper
\\
  Medical instrument detection is essential for computer-assisted interventions
since it would facilitate the surgeons to find the instrument efficiently with
a better interpretation, which leads to a better outcome. This article reviews
medical instrument detection methods in the ultrasound-guided intervention.
First, we present a comprehensive review of instrument detection methodologies,
which include traditional non-data-driven methods and data-driven methods. The
non-data-driven methods were extensively studied prior to the era of machine
learning, i.e. data-driven approaches. We discuss the main clinical
applications of medical instrument detection in ultrasound, including
anesthesia, biopsy, prostate brachytherapy, and cardiac catheterization, which
were validated on clinical datasets. Finally, we selected several principal
publications to summarize the key issues and potential research directions for
the computer-assisted intervention community.
\\ ( https://arxiv.org/abs/2007.04807 ,  3877kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04873 (*cross-listing*)
Date: Thu, 9 Jul 2020 15:21:28 GMT   (7422kb,D)

Title: Invertible Zero-Shot Recognition Flows
Authors: Yuming Shen, Jie Qin, Lei Huang
Categories: cs.LG cs.CV stat.ML
Comments: ECCV2020
\\
  Deep generative models have been successfully applied to Zero-Shot Learning
(ZSL) recently. However, the underlying drawbacks of GANs and VAEs (e.g., the
hardness of training with ZSL-oriented regularizers and the limited generation
quality) hinder the existing generative ZSL models from fully bypassing the
seen-unseen bias. To tackle the above limitations, for the first time, this
work incorporates a new family of generative models (i.e., flow-based models)
into ZSL. The proposed Invertible Zero-shot Flow (IZF) learns factorized data
embeddings (i.e., the semantic factors and the non-semantic ones) with the
forward pass of an invertible flow network, while the reverse pass generates
data samples. This procedure theoretically extends conventional generative
flows to a factorized conditional scheme. To explicitly solve the bias problem,
our model enlarges the seen-unseen distributional discrepancy based on negative
sample-based distance measurement. Notably, IZF works flexibly with either a
naive Bayesian classifier or a held-out trainable one for zero-shot
recognition. Experiments on widely-adopted ZSL benchmarks demonstrate the
significant performance gain of IZF over existing methods, in both classic and
generalized settings.
\\ ( https://arxiv.org/abs/2007.04873 ,  7422kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04976 (*cross-listing*)
Date: Thu, 9 Jul 2020 17:59:35 GMT   (5768kb,D)

Title: One Policy to Control Them All: Shared Modular Policies for
  Agent-Agnostic Control
Authors: Wenlong Huang, Igor Mordatch, Deepak Pathak
Categories: cs.LG cs.CV stat.ML
Comments: Accepted at ICML 2020. Videos and code at
  https://huangwl18.github.io/modular-rl/
\\
  Reinforcement learning is typically concerned with learning control policies
tailored to a particular agent. We investigate whether there exists a single
global policy that can generalize to control a wide variety of agent
morphologies -- ones in which even dimensionality of state and action spaces
changes. We propose to express this global policy as a collection of identical
modular neural networks, dubbed as Shared Modular Policies (SMP), that
correspond to each of the agent's actuators. Every module is only responsible
for controlling its corresponding actuator and receives information from only
its local sensors. In addition, messages are passed between modules,
propagating information between distant modules. We show that a single modular
policy can successfully generate locomotion behaviors for several planar agents
with different skeletal structures such as monopod hoppers, quadrupeds, bipeds,
and generalize to variants not seen during training -- a process that would
normally require training and manual hyperparameter tuning for each morphology.
We observe that a wide variety of drastically diverse locomotion styles across
morphologies as well as centralized coordination emerges via message passing
between decentralized modules purely from the reinforcement learning objective.
Videos and code at https://huangwl18.github.io/modular-rl/
\\ ( https://arxiv.org/abs/2007.04976 ,  5768kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04513 (*cross-listing*)
Date: Thu, 9 Jul 2020 02:25:25 GMT   (190kb,D)

Title: Computing the Largest Bond and the Maximum Connected Cut of a Graph
Authors: Gabriel L. Duarte, Hiroshi Eto, Tesshu Hanaka, Yasuaki Kobayashi,
  Yusuke Kobayashi, Daniel Lokshtanov, Lehilton L. C. Pedrosa, Rafael C. S.
  Schouery, and U\'everton S. Souza
Categories: cs.DS cs.CC cs.DM
Comments: This paper resulted from a merge of two papers submitted to arXiv
  (arXiv:1908.03389 and arXiv:1910.01071). Both preliminary versions were
  presented at the 14th International Symposium on Parameterized and Exact
  Computation (IPEC 2019)
\\
  The cut-set $\partial(S)$ of a graph $G=(V,E)$ is the set of edges that have
one endpoint in $S\subset V$ and the other endpoint in $V\setminus S$, and
whenever $G[S]$ is connected, the cut $[S,V\setminus S]$ of $G$ is called a
connected cut. A bond of a graph $G$ is an inclusion-wise minimal disconnecting
set of $G$, i.e., bonds are cut-sets that determine cuts $[S,V\setminus S]$ of
$G$ such that $G[S]$ and $G[V\setminus S]$ are both connected. Contrasting with
a large number of studies related to maximum cuts, there exist very few results
regarding the largest bond of general graphs. In this paper, we aim to reduce
this gap on the complexity of computing the largest bond, and the maximum
connected cut of a graph. Although cuts and bonds are similar, we remark that
computing the largest bond and the maximum connected cut of a graph tends to be
harder than computing its maximum cut. We show that it does not exist a
constant-factor approximation algorithm to compute the largest bond, unless P =
NP. Also, we show that {\sc Largest Bond} and {\sc Maximum Connected Cut} are
NP-hard even for planar bipartite graphs, whereas \textsc{Maximum Cut} is
trivial on bipartite graphs and polynomial-time solvable on planar graphs. In
addition, we show that {\sc Largest Bond} and {\sc Maximum Connected Cut} are
NP-hard on split graphs, and restricted to graphs of clique-width $w$ they can
not be solved in time $f(w)\times n^{o(w)}$ unless the Exponential Time
Hypothesis fails, but they can be solved in time $f(w)\times n^{O(w)}$.
Finally, we show that both problems are fixed-parameter tractable when
parameterized by the size of the solution, the treewidth, and the twin-cover
number.
\\ ( https://arxiv.org/abs/2007.04513 ,  190kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04715 (*cross-listing*)
Date: Thu, 9 Jul 2020 11:29:48 GMT   (37kb,D)

Title: Order-sensitive domination in partially ordered sets
Authors: Yusuf Civan, Zakir Deniz, Mehmet Akif Yetim
Categories: math.CO cs.DM
Comments: 23 pages, 9 figures
MSC-class: 05C69, 06A07, 68Q17
\\
  For a (finite) partially ordered set (poset) $P$, we call a dominating set
$D$ in the comparability graph $Comp(P)$ of $P$, an order-sensitive dominating
set in $P$ if either $x\in D$ or else $a<x<b$ in $P$ for some $a,b\in D$ for
every element $x$ in $P$ which is neither maximal nor minimal, and denote by
$\gamma_{os}(P)$, the least size of an order-sensitive dominating set of $P$.
For every graph $G$ and integer $k\geq 2$, we associate a graded poset
$\mathscr{P}_k(G)$ of height $k$, and prove that
$\gamma_{os}(\mathscr{P}_3(G))=\gamma_{\text{R}}(G)$ and
$\gamma_{os}(\mathscr{P}_4(G))=2\gamma(G)$ hold, where $\gamma(G)$ and
$\gamma_{\text{R}}(G)$ are the domination and Roman domination number of $G$,
respectively. Apart from these, we introduce the notion of a Helly poset, and
prove that when $P$ is a Helly poset, the computation of order-sensitive
domination number of $P$ can be interpreted as a weighted clique partition
number of a graph, the middle graph of $P$. Moreover, we show that the
order-sensitive domination number of a poset $P$ exactly corresponds to the
biclique vertex-partition number of the associated bipartite transformation of
$P$. Finally, we prove that the decision problem of order-sensitive domination
on posets of arbitrary height is NP-complete, which is obtained by using a
reduction from EQUAL-$3$-SAT problem.
\\ ( https://arxiv.org/abs/2007.04715 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04837 (*cross-listing*)
Date: Thu, 9 Jul 2020 14:35:10 GMT   (27kb)

Title: Geometric Bounds for Convergence Rates of Averaging Algorithms
Authors: Bernadette Charron-Bost
Categories: cs.MA cs.DM
\\
  We develop a generic method for bounding the convergence rate of an averaging
algorithm running in a multi-agent system with a time-varying network, where
the associated stochastic matrices have a time-independent Perron vector. This
method provides bounds on convergence rates that unify and refine most of the
previously known bounds. They depend on geometric parameters of the dynamic
communication graph such as the normalized diameter or the bottleneck measure.
  As corollaries of these geometric bounds, we show that the convergence rate
of the Metropolis algorithm in a system of $n$ agents is less than $1-1/4n^2$
with any communication graph that may vary in time, but is permanently
connected and bidirectional. We prove a similar upper bound for the
EqualNeighbor algorithm under the additional assumptions that the number of
neighbors of each agent is constant and that the communication graph is not too
irregular. Moreover our bounds offer improved convergence rates for several
averaging algorithms and specific families of communication graphs.
  Finally we extend our methodology to a time-varying Perron vector and show
how convergence times may dramatically degrade with even limited variations of
Perron vectors.
\\ ( https://arxiv.org/abs/2007.04837 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04948 (*cross-listing*)
Date: Thu, 9 Jul 2020 17:21:56 GMT   (676kb,D)

Title: Bribery and Control in Stable Marriage
Authors: Niclas Boehmer, Robert Bredereck, Klaus Heeger and Rolf Niedermeier
Categories: cs.GT cs.DM
Comments: Accepted to SAGT 2020
\\
  We initiate the study of external manipulations in Stable Marriage by
considering several manipulative actions as well as several "desirable"
manipulation goals. For instance, one goal is to make sure that a given pair of
agents is matched in a stable solution, and this may be achieved by the
manipulative action of reordering some agents' preference lists. We present a
comprehensive study of the computational complexity of all problems arising in
this way. We find several polynomial-time solvable cases as well as NP-hard
ones. For the NP-hard cases, focusing on the natural parameter "budget" (that
is, the number of manipulative actions), we also perform a parameterized
complexity analysis and encounter parameterized hardness results.
\\ ( https://arxiv.org/abs/2007.04948 ,  676kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04570 (*cross-listing*)
Date: Thu, 9 Jul 2020 05:52:41 GMT   (6402kb,D)

Title: A Secure Back-up and Restore for Resource-Constrained IoT based on
  Nanotechnology
Authors: Mesbah Uddin, Md. Badruddoja Majumder, Md. Sakib Hasan, Garrett S.
  Rose
Categories: cs.CR cs.ET
Comments: Content: 17 pages with 15 figures and 7 tables Submitted to IEEE IoT
  Journal
\\
  With the emergence of IoT (Internet of things), huge amounts of sensitive
data are being processed and transmitted everyday in edge devices with little
to no security. Due to their aggressive power management schemes, it is a
common and necessary technique to make a back-up of their program states and
other necessary data in a non-volatile memory (NVM) before going to sleep or
low power mode. However, this memory is often left unprotected as adding robust
security measures tends to be expensive for these resource constrained systems.
In this paper, we propose a lightweight security system for NVM during low
power mode. This security architecture uses the memristor, an emerging
nanoscale device which is used to build hardware security primitives like PUF
(physical unclonable function) based encryption-decryption, true random number
generators (TRNG), and memory integrity checking. A reliability enhancement
technique for this PUF is also proposed which shows how this system would work
even with less-than-100\% reliable PUF responses. Together, with all these
techniques, we have established a dual layer security protocol (data
encryption+integrity check) which provides reasonable security to an embedded
processor while being very lightweight in terms of area, power, and computation
time. A complete system design is demonstrated with 65$n$m CMOS and emerging
memristive technology. With this, we have provided a detailed and accurate
estimation of resource overhead. Analysis of the security of the whole system
is also provided.
\\ ( https://arxiv.org/abs/2007.04570 ,  6402kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2003.04740
replaced with revised version Thu, 9 Jul 2020 10:43:50 GMT   (609kb,D)

Title: Drawing Graphs with Circular Arcs and Right-Angle Crossings
Authors: Steven Chaplick, Henry F\"orster, Myroslav Kryven, Alexander Wolff
Categories: cs.CG
Journal-ref: Proc. 17th Scandinavian Symposium and Workshops on Algorithm
  Theory (SWAT 2020), LIPIcs 162, pages 21:1-21:14
DOI: 10.4230/LIPIcs.SWAT.2020.21
\\ ( https://arxiv.org/abs/2003.04740 ,  609kb)
------------------------------------------------------------------------------
\\
arXiv:2005.02819
replaced with revised version Thu, 9 Jul 2020 06:55:00 GMT   (2823kb,D)

Title: Geoopt: Riemannian Optimization in PyTorch
Authors: Max Kochurov, Rasul Karimov, Serge Kozlukov
Categories: cs.CG cs.LG
Comments: Proceedings of the 37th International Conference on Machine Learning,
  Vienna, Austria, PMLR 108, 2020, GRLB Workshop
MSC-class: 53-04
ACM-class: G.4
\\ ( https://arxiv.org/abs/2005.02819 ,  2823kb)
------------------------------------------------------------------------------
\\
arXiv:1208.6335
replaced with revised version Thu, 9 Jul 2020 01:34:05 GMT   (992kb)

Title: Comparative Study and Optimization of Feature-Extraction Techniques for
  Content based Image Retrieval
Authors: Aman Chadha, Sushmit Mallik and Ravdeep Johar
Categories: cs.CV cs.AI cs.IR cs.LG cs.MM
Comments: 8 pages, 16 figures, 11 tables
Report-no: Volume 52, Number 20, 2012
Journal-ref: International Journal of Computer Applications 52(20):35-42, 2012
DOI: 10.5120/8320-1959
\\ ( https://arxiv.org/abs/1208.6335 ,  992kb)
------------------------------------------------------------------------------
\\
arXiv:1807.04892
replaced with revised version Thu, 9 Jul 2020 16:31:32 GMT   (677kb)

Title: Computer Analysis of Architecture Using Automatic Image Understanding
Authors: Fan Wei, Yuan Li, Lior Shamir
Categories: cs.CV
Journal-ref: Journal of Data Mining & Digital Humanities, 2018 (January 22,
  2019) jdmdh:5030
\\ ( https://arxiv.org/abs/1807.04892 ,  677kb)
------------------------------------------------------------------------------
\\
arXiv:1811.11721
replaced with revised version Thu, 9 Jul 2020 12:17:28 GMT   (2438kb,D)

Title: CCNet: Criss-Cross Attention for Semantic Segmentation
Authors: Zilong Huang, Xinggang Wang, Yunchao Wei, Lichao Huang, Humphrey Shi,
  Wenyu Liu, Thomas S. Huang
Categories: cs.CV
Comments: IEEE TPAMI 2020 & ICCV 2019
\\ ( https://arxiv.org/abs/1811.11721 ,  2438kb)
------------------------------------------------------------------------------
\\
arXiv:1905.07553
replaced with revised version Thu, 9 Jul 2020 06:07:41 GMT   (4951kb,D)

Title: Which Tasks Should Be Learned Together in Multi-task Learning?
Authors: Trevor Standley, Amir R. Zamir, Dawn Chen, Leonidas Guibas, Jitendra
  Malik and Silvio Savarese
Categories: cs.CV
Comments: Accepted to ICML 2020 See project website at
  http://taskgrouping.stanford.edu/
\\ ( https://arxiv.org/abs/1905.07553 ,  4951kb)
------------------------------------------------------------------------------
\\
arXiv:1905.11503
replaced with revised version Thu, 9 Jul 2020 12:11:55 GMT   (6138kb,D)

Title: Body Shape Privacy in Images: Understanding Privacy and Preventing
  Automatic Shape Extraction
Authors: Hosnieh Sattar, Katharina Krombholz, Gerard Pons-Moll, Mario Fritz
Categories: cs.CV cs.AI cs.CR cs.LG
\\ ( https://arxiv.org/abs/1905.11503 ,  6138kb)
------------------------------------------------------------------------------
\\
arXiv:1906.01916
replaced with revised version Wed, 8 Jul 2020 22:34:51 GMT   (1746kb,D)

Title: Semi-supervised semantic segmentation needs strong, varied perturbations
Authors: Geoff French, Samuli Laine, Timo Aila, Michal Mackiewicz and Graham
  Finlayson
Categories: cs.CV
Comments: 19 pages, 5 figures, submitted to BMVC 2020
\\ ( https://arxiv.org/abs/1906.01916 ,  1746kb)
------------------------------------------------------------------------------
\\
arXiv:1909.11065
replaced with revised version Thu, 9 Jul 2020 16:06:28 GMT   (1310kb,D)

Title: Object-Contextual Representations for Semantic Segmentation
Authors: Yuhui Yuan, Xilin Chen, Jingdong Wang
Categories: cs.CV
Comments: ECCV 2020 Spotlight. Project Page:
  https://github.com/openseg-group/openseg.pytorch;
  https://github.com/HRNet/HRNet-Semantic-Segmentation/tree/HRNet-OCR
Journal-ref: ECCV 2020
\\ ( https://arxiv.org/abs/1909.11065 ,  1310kb)
------------------------------------------------------------------------------
\\
arXiv:1911.05055
replaced with revised version Thu, 9 Jul 2020 17:49:59 GMT   (2122kb)

Title: A convolutional neural network reaches optimal sensitivity for detecting
  some, but not all, patterns
Authors: Fabian H. Reith and Brian A. Wandell
Categories: cs.CV
Comments: 22 pages, 8 figures, pre-print
\\ ( https://arxiv.org/abs/1911.05055 ,  2122kb)
------------------------------------------------------------------------------
\\
arXiv:2001.06902
replaced with revised version Wed, 8 Jul 2020 19:58:22 GMT   (5769kb,D)

Title: MTI-Net: Multi-Scale Task Interaction Networks for Multi-Task Learning
Authors: Simon Vandenhende, Stamatios Georgoulis and Luc Van Gool
Categories: cs.CV
Comments: Accepted at ECCV2020 (spotlight) - Code:
  https://github.com/SimonVandenhende/Multi-Task-Learning-PyTorch
\\ ( https://arxiv.org/abs/2001.06902 ,  5769kb)
------------------------------------------------------------------------------
\\
arXiv:2003.03653
replaced with revised version Thu, 9 Jul 2020 10:07:58 GMT   (1870kb,D)

Title: SalsaNext: Fast, Uncertainty-aware Semantic Segmentation of LiDAR Point
  Clouds for Autonomous Driving
Authors: Tiago Cortinhal, George Tzelepis and Eren Erdal Aksoy
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2003.03653 ,  1870kb)
------------------------------------------------------------------------------
\\
arXiv:2003.04253
replaced with revised version Thu, 9 Jul 2020 17:34:32 GMT   (9240kb,D)

Title: Motion-Attentive Transition for Zero-Shot Video Object Segmentation
Authors: Tianfei Zhou, Shunzhou Wang, Yi Zhou, Yazhou Yao, Jianwu Li, Ling Shao
Categories: cs.CV cs.LG eess.IV
Comments: AAAI 2020. Code: https://github.com/tfzhou/MATNet
\\ ( https://arxiv.org/abs/2003.04253 ,  9240kb)
------------------------------------------------------------------------------
\\
arXiv:2003.04719
replaced with revised version Thu, 9 Jul 2020 10:32:06 GMT   (842kb,D)

Title: Dual-attention Guided Dropblock Module for Weakly Supervised Object
  Localization
Authors: Junhui Yin, Siqing Zhang, Dongliang Chang, Zhanyu Ma, Jun Guo
Categories: cs.CV
Comments: Accepted by the 25th International Conference on Pattern Recognition
  (ICPR 2020)
\\ ( https://arxiv.org/abs/2003.04719 ,  842kb)
------------------------------------------------------------------------------
\\
arXiv:2003.08799
replaced with revised version Thu, 9 Jul 2020 06:52:34 GMT   (185kb,D)

Title: Pedestrian Detection: The Elephant In The Room
Authors: Irtiza Hasan, Shengcai Liao, Jinpeng Li, Saad Ullah Akram, and Ling
  Shao
Categories: cs.CV
Comments: 17 pages, 1 figure
\\ ( https://arxiv.org/abs/2003.08799 ,  185kb)
------------------------------------------------------------------------------
\\
arXiv:2003.10281
replaced with revised version Wed, 8 Jul 2020 20:22:14 GMT   (5708kb,D)

Title: Accurate Optimization of Weighted Nuclear Norm for Non-Rigid Structure
  from Motion
Authors: Jos\'e Pedro Iglesias, Carl Olsson, Marcus Valtonen \"Ornhag
Categories: cs.CV math.OC
\\ ( https://arxiv.org/abs/2003.10281 ,  5708kb)
------------------------------------------------------------------------------
\\
arXiv:2003.13502
replaced with revised version Thu, 9 Jul 2020 17:25:26 GMT   (3631kb,D)

Title: An Open-source Tool for Hyperspectral Image Augmentation in Tensorflow
Authors: Mohamed Abdelhack
Categories: cs.CV cs.LG eess.IV
\\ ( https://arxiv.org/abs/2003.13502 ,  3631kb)
------------------------------------------------------------------------------
\\
arXiv:2004.02684
replaced with revised version Thu, 9 Jul 2020 09:52:23 GMT   (4324kb,D)

Title: Attribute Mix: Semantic Data Augmentation for Fine Grained Recognition
Authors: Hao Li, Xiaopeng Zhang, Hongkai Xiong, Qi Tian
Categories: cs.CV
\\ ( https://arxiv.org/abs/2004.02684 ,  4324kb)
------------------------------------------------------------------------------
\\
arXiv:2006.01645
replaced with revised version Thu, 9 Jul 2020 11:26:17 GMT   (4708kb,D)

Title: Interpretation of ResNet by Visualization of Preferred Stimulus in
  Receptive Fields
Authors: Genta Kobayashi and Hayaru Shouno
Categories: cs.CV
Comments: 10 pages
\\ ( https://arxiv.org/abs/2006.01645 ,  4708kb)
------------------------------------------------------------------------------
\\
arXiv:2006.02597
replaced with revised version Wed, 8 Jul 2020 19:56:58 GMT   (5028kb,D)

Title: COMET: Context-Aware IoU-Guided Network for Small Object Tracking
Authors: Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Hossein Ghanei-Yakhdan,
  Shohreh Kasaei, and Li Cheng
Categories: cs.CV eess.IV
\\ ( https://arxiv.org/abs/2006.02597 ,  5028kb)
------------------------------------------------------------------------------
\\
arXiv:2006.03926
replaced with revised version Thu, 9 Jul 2020 06:21:08 GMT   (2713kb,D)

Title: Self-supervising Fine-grained Region Similarities for Large-scale Image
  Localization
Authors: Yixiao Ge, Haibo Wang, Feng Zhu, Rui Zhao, Hongsheng Li
Categories: cs.CV
Comments: Accepted in ECCV 2020 (Spotlight), code is available at
  https://github.com/yxgeee/SFRS
\\ ( https://arxiv.org/abs/2006.03926 ,  2713kb)
------------------------------------------------------------------------------
\\
arXiv:2006.10721
replaced with revised version Thu, 9 Jul 2020 17:00:21 GMT   (3947kb,D)

Title: Ocean: Object-aware Anchor-free Tracking
Authors: Zhipeng Zhang, Houwen Peng, Jianlong Fu, Bing Li, Weiming Hu
Categories: cs.CV
Comments: Accepted by ECCV2020
Journal-ref: ECCV2020
\\ ( https://arxiv.org/abs/2006.10721 ,  3947kb)
------------------------------------------------------------------------------
\\
arXiv:2006.13681
replaced with revised version Thu, 9 Jul 2020 03:29:57 GMT   (4486kb,D)

Title: Multi-view Drone-based Geo-localization via Style and Spatial Alignment
Authors: Siyi Hu and Xiaojun Chang
Categories: cs.CV cs.LG stat.ML
Comments: 9 pages 9 figures. arXiv admin note: text overlap with
  arXiv:2002.12186 by other authors
ACM-class: I.4.7; I.2.10
\\ ( https://arxiv.org/abs/2006.13681 ,  4486kb)
------------------------------------------------------------------------------
\\
arXiv:2006.14090
replaced with revised version Wed, 8 Jul 2020 18:11:08 GMT   (876kb,D)

Title: Neural Architecture Design for GPU-Efficient Networks
Authors: Ming Lin, Hesen Chen, Xiuyu Sun, Qi Qian, Hao Li, Rong Jin
Categories: cs.CV
\\ ( https://arxiv.org/abs/2006.14090 ,  876kb)
------------------------------------------------------------------------------
\\
arXiv:2006.15190
replaced with revised version Thu, 9 Jul 2020 11:33:27 GMT   (7731kb,D)

Title: Making DensePose fast and light
Authors: Ruslan Rakhimov, Emil Bogomolov, Alexandr Notchenko, Fung Mao, Alexey
  Artemov, Denis Zorin, Evgeny Burnaev
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2006.15190 ,  7731kb)
------------------------------------------------------------------------------
\\
arXiv:2006.16471
replaced with revised version Wed, 8 Jul 2020 19:06:43 GMT   (9247kb,D)

Title: Object Detection under Rainy Conditions for Autonomous Vehicles
Authors: Mazin Hnewa and Hayder Radha
Categories: cs.CV
Comments: Accepted in IEEE Signal Processing Magazine / Special Issue on
  Autonomous Driving
\\ ( https://arxiv.org/abs/2006.16471 ,  9247kb)
------------------------------------------------------------------------------
\\
arXiv:2007.01546
replaced with revised version Thu, 9 Jul 2020 13:42:38 GMT   (1488kb,D)

Title: Multiple Expert Brainstorming for Domain Adaptive Person
  Re-identification
Authors: Yunpeng Zhai, Qixiang Ye, Shijian Lu, Mengxi Jia, Rongrong Ji and
  Yonghong Tian
Categories: cs.CV
Comments: Accepted by ECCV'20
\\ ( https://arxiv.org/abs/2007.01546 ,  1488kb)
------------------------------------------------------------------------------
\\
arXiv:2007.02149
replaced with revised version Wed, 8 Jul 2020 18:33:35 GMT   (142kb)

Title: Human Assisted Artificial Intelligence Based Technique to Create Natural
  Features for OpenStreetMap
Authors: Piyush Yadav, Dipto Sarkar, Shailesh Deshpande, Edward Curry
Categories: cs.CV cs.AI cs.CY
Comments: 3 pages, 2 Figures, Submitted to FOSS4G Europe 2020 Academic Track
  (Postponed to 2021)
\\ ( https://arxiv.org/abs/2007.02149 ,  142kb)
------------------------------------------------------------------------------
\\
arXiv:2007.02433
replaced with revised version Wed, 8 Jul 2020 18:05:41 GMT   (0kb,I)

Title: Estimation of Ground Contacts from Human Gait by a Wearable Inertial
  Measurement Unit using machine learning
Authors: Muhammad Junaid Umer and Qaiser Riaz
Categories: cs.CV cs.LG
Comments: Not completely discussed with supervisor need some improvements in
  article to prepare a final draft
\\ ( https://arxiv.org/abs/2007.02433 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2007.03506
replaced with revised version Thu, 9 Jul 2020 15:14:19 GMT   (5499kb,D)

Title: Hierarchical nucleation in deep neural networks
Authors: Diego Doimo, Aldo Glielmo, Alessio Ansuini, Alessandro Laio
Categories: cs.CV cs.LG stat.ML
\\ ( https://arxiv.org/abs/2007.03506 ,  5499kb)
------------------------------------------------------------------------------
\\
arXiv:2007.03777
replaced with revised version Thu, 9 Jul 2020 08:17:10 GMT   (4097kb,D)

Title: Placepedia: Comprehensive Place Understanding with Multi-Faceted
  Annotations
Authors: Huaiyi Huang, Yuqi Zhang, Qingqiu Huang, Zhengkui Guo, Ziwei Liu, and
  Dahua Lin
Categories: cs.CV cs.CL cs.IR
Comments: To appear in ECCV 2020. Dataset is available at:
  https://hahehi.github.io/placepedia.html
\\ ( https://arxiv.org/abs/2007.03777 ,  4097kb)
------------------------------------------------------------------------------
\\
arXiv:2007.04269
replaced with revised version Thu, 9 Jul 2020 16:02:08 GMT   (2915kb,D)

Title: SegFix: Model-Agnostic Boundary Refinement for Segmentation
Authors: Yuhui Yuan, Jingyi Xie, Xilin Chen, Jingdong Wang
Categories: cs.CV
Comments: ECCV 2020. Project Page:
  https://github.com/openseg-group/openseg.pytorch
\\ ( https://arxiv.org/abs/2007.04269 ,  2915kb)
------------------------------------------------------------------------------
\\
arXiv:1905.05304
replaced with revised version Thu, 9 Jul 2020 15:16:20 GMT   (160kb,D)

Title: Computing Maximum Matchings in Temporal Graphs
Authors: George B. Mertzios, Hendrik Molter, Rolf Niedermeier, Viktor Zamaraev,
  and Philipp Zschoche
Categories: cs.DM cs.CC cs.DS
\\ ( https://arxiv.org/abs/1905.05304 ,  160kb)
------------------------------------------------------------------------------
\\
arXiv:1812.10354
replaced with revised version Mon, 6 Jul 2020 20:04:38 GMT   (1736kb)

Title: Single Flux Quantum Based Ultrahigh Speed Spiking Neuromorphic Processor
  Architecture
Authors: Ali Bozbey, Mustafa Altay Karamuftuoglu, Sasan Razmkhah, Murat
  Ozbayoglu
Categories: cs.ET physics.app-ph
\\ ( https://arxiv.org/abs/1812.10354 ,  1736kb)
------------------------------------------------------------------------------
\\
arXiv:2003.11011
replaced with revised version Tue, 7 Jul 2020 13:38:00 GMT   (623kb,D)

Title: Probabilistic Memristive Networks: Application of a Master Equation to
  Networks of Binary ReRAM cells
Authors: V. J. Dowling, V. A. Slipko, and Y. V. Pershin
Categories: cs.ET cond-mat.mes-hall cond-mat.mtrl-sci
\\ ( https://arxiv.org/abs/2003.11011 ,  623kb)
------------------------------------------------------------------------------
\\
arXiv:2007.00776
replaced with revised version Mon, 6 Jul 2020 20:03:32 GMT   (2825kb,D)

Title: Emulation of Astrocyte Induced Neural Phase Synchrony in Spin-Orbit
  Torque Oscillator Neurons
Authors: Umang Garg, Kezhou Yang, Abhronil Sengupta
Categories: cs.ET q-bio.NC
\\ ( https://arxiv.org/abs/2007.00776 ,  2825kb)
------------------------------------------------------------------------------
\\
arXiv:1901.02221
replaced with revised version Thu, 9 Jul 2020 15:00:54 GMT   (7321kb,D)

Title: A Survey of Biological Building Blocks for Synthetic Molecular
  Communication Systems
Authors: Christian A. S\"oldner, Eileen Socher, Vahid Jamali, Wayan Wicke,
  Arman Ahmadzadeh, Hans-Georg Breitinger, Andreas Burkovski, Kathrin
  Castiglione, Robert Schober, Heinrich Sticht
Categories: cs.ET
Comments: 70 pages, 11 figures, 9 tables; Accepted for publication in the IEEE
  Communications Surveys & Tutorials
\\ ( https://arxiv.org/abs/1901.02221 ,  7321kb)
------------------------------------------------------------------------------
\\
arXiv:2002.01932
replaced with revised version Thu, 9 Jul 2020 06:00:01 GMT   (4698kb,D)

Title: Hybrid Pass Transistor Logic with Ambipolar Transistors
Authors: Xuan Hu, Amy S. Abraham, Jean Anne C. Incorvia, Joseph S. Friedman
Categories: cs.ET
\\ ( https://arxiv.org/abs/2002.01932 ,  4698kb)
------------------------------------------------------------------------------
\\
arXiv:1910.00780 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 02:51:57 GMT   (6144kb,D)

Title: How Does Topology of Neural Architectures Impact Gradient Propagation
  and Model Performance?
Authors: Kartikeya Bhardwaj, Guihong Li, Radu Marculescu
Categories: stat.ML cs.CV cs.LG
\\ ( https://arxiv.org/abs/1910.00780 ,  6144kb)
------------------------------------------------------------------------------
\\
arXiv:1912.00515 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 02:00:40 GMT   (4594kb,D)

Title: Texture Hallucination for Large-Factor Painting Super-Resolution
Authors: Yulun Zhang, Zhifei Zhang, Stephen DiVerdi, Zhaowen Wang, Jose
  Echevarria, Yun Fu
Categories: eess.IV cs.CV
Comments: Accepted to ECCV 2020. Supplementary material contains more visual
  results and is available at
  http://yulunzhang.com/papers/PaintingSR_supp_arXiv.pdf
\\ ( https://arxiv.org/abs/1912.00515 ,  4594kb)
------------------------------------------------------------------------------
\\
arXiv:1912.10557 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 16:26:41 GMT   (8185kb,D)

Title: Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal
  and Image Processing
Authors: Vishal Monga, Yuelong Li and Yonina C. Eldar
Categories: eess.IV cs.CV cs.LG eess.SP
\\ ( https://arxiv.org/abs/1912.10557 ,  8185kb)
------------------------------------------------------------------------------
\\
arXiv:2001.04537 (*cross-listing*)
replaced with revised version Wed, 8 Jul 2020 21:26:34 GMT   (1090kb)

Title: Efficient convolutional neural networks for multi-planar lung nodule
  detection: improvement on small nodule identification
Authors: Sunyi Zheng, Ludo J. Cornelissen, Xiaonan Cui, Xueping Jing, Raymond
  N. J. Veldhuis, Matthijs Oudkerk, and Peter M.A. van Ooijen
Categories: eess.IV cs.CV cs.LG
\\ ( https://arxiv.org/abs/2001.04537 ,  1090kb)
------------------------------------------------------------------------------
\\
arXiv:2002.10099
replaced with revised version Thu, 9 Jul 2020 12:32:45 GMT   (8207kb,D)

Title: Implicit Geometric Regularization for Learning Shapes
Authors: Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, Yaron Lipman
Categories: cs.LG cs.CV cs.GR stat.ML
Comments: 37th International Conference on Machine Learning, Vienna, Austria,
  2020
\\ ( https://arxiv.org/abs/2002.10099 ,  8207kb)
------------------------------------------------------------------------------
\\
arXiv:2003.03233 (*cross-listing*)
replaced with revised version Wed, 8 Jul 2020 21:19:38 GMT   (4164kb,D)

Title: Anysize GAN: A solution to the image-warping problem
Authors: Connah Kendrick, David Gillespie, Moi Hoon Yap
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2003.03233 ,  4164kb)
------------------------------------------------------------------------------
\\
arXiv:2003.11013 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 13:57:11 GMT   (720kb,D)

Title: Tractogram filtering of anatomically non-plausible fibers with geometric
  deep learning
Authors: Pietro Astolfi, Ruben Verhagen, Laurent Petit, Emanuele Olivetti,
  Jonathan Masci, Davide Boscaini, Paolo Avesani
Categories: q-bio.NC cs.CV eess.IV
Comments: Accepted at MICCAI2020
\\ ( https://arxiv.org/abs/2003.11013 ,  720kb)
------------------------------------------------------------------------------
\\
arXiv:2004.04617 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 09:06:55 GMT   (3402kb,D)

Title: Cortical surface registration using unsupervised learning
Authors: Jieyu Cheng, Adrian V. Dalca, Bruce Fischl, Lilla Zollei (for the
  Alzheimer's Disease Neuroimaging Initiative)
Categories: eess.IV cs.CV q-bio.NC
Comments: cortical surface registration, deep network, unsupervised learning,
  registration, deep learning, cortical, spherical, invertible
\\ ( https://arxiv.org/abs/2004.04617 ,  3402kb)
------------------------------------------------------------------------------
\\
arXiv:2004.05024 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 16:47:54 GMT   (3066kb,D)

Title: Weakly supervised multiple instance learning histopathological tumor
  segmentation
Authors: Marvin Lerousseau, Maria Vakalopoulou, Marion Classe, Julien Adam,
  Enzo Battistella, Alexandre Carr\'e, Th\'eo Estienne, Th\'eophraste Henry,
  Eric Deutsch and Nikos Paragios
Categories: eess.IV cs.CV cs.LG
Comments: Accepted MICCAI 2020; added code + results url; 10 pages, 3 figures
\\ ( https://arxiv.org/abs/2004.05024 ,  3066kb)
------------------------------------------------------------------------------
\\
arXiv:2004.05717 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 15:43:10 GMT   (1586kb,D)

Title: Towards an Effective and Efficient Deep Learning Model for COVID-19
  Patterns Detection in X-ray Images
Authors: Eduardo Luz, Pedro Lopes Silva, Rodrigo Silva, Ludmila Silva, Gladston
  Moreira and David Menotti
Categories: eess.IV cs.CV cs.LG
Comments: 31 pages, 9 figures
\\ ( https://arxiv.org/abs/2004.05717 ,  1586kb)
------------------------------------------------------------------------------
\\
arXiv:2004.14858
replaced with revised version Thu, 9 Jul 2020 08:37:43 GMT   (1424kb,D)

Title: MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop
Authors: Lukas Stappen, Alice Baird, Georgios Rizos, Panagiotis Tzirakis,
  Xinchen Du, Felix Hafner, Lea Schumann, Adria Mallol-Ragolta, Bj\"orn W.
  Schuller, Iulia Lefter, Erik Cambria, Ioannis Kompatsiaris
Categories: cs.MM cs.CL cs.CV cs.SD eess.AS
Comments: Baseline Paper MuSe 2020, MuSe Workshop Challenge, ACM Multimedia
\\ ( https://arxiv.org/abs/2004.14858 ,  1424kb)
------------------------------------------------------------------------------
\\
arXiv:2006.04878 (*cross-listing*)
replaced with revised version Wed, 8 Jul 2020 21:20:48 GMT   (4631kb,D)

Title: KiU-Net: Towards Accurate Segmentation of Biomedical Images using
  Over-complete Representations
Authors: Jeya Maria Jose, Vishwanath Sindagi, Ilker Hacihaliloglu, Vishal M.
  Patel
Categories: eess.IV cs.CV
Comments: Accepted at MICCAI 2020
\\ ( https://arxiv.org/abs/2006.04878 ,  4631kb)
------------------------------------------------------------------------------
\\
arXiv:2006.13811 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 10:59:55 GMT   (334kb,D)

Title: Interpretable Deep Models for Cardiac Resynchronisation Therapy Response
  Prediction
Authors: Esther Puyol-Ant\'on, Chen Chen, James R. Clough, Bram Ruijsink,
  Baldeep S. Sidhu, Justin Gould, Bradley Porter, Mark Elliott, Vishal Mehta,
  Daniel Rueckert, Christopher A. Rinaldi, and Andrew P. King
Categories: eess.IV cs.CV cs.LG
Comments: MICCAI 2020 conference
\\ ( https://arxiv.org/abs/2006.13811 ,  334kb)
------------------------------------------------------------------------------
\\
arXiv:2006.16581 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 02:47:20 GMT   (2297kb,D)

Title: Early Exit Or Not: Resource-Efficient Blind Quality Enhancement for
  Compressed Images
Authors: Qunliang Xing, Mai Xu, Tianyi Li, Zhenyu Guan
Categories: eess.IV cs.CV
Comments: Accepted by ECCV 2020
\\ ( https://arxiv.org/abs/2006.16581 ,  2297kb)
------------------------------------------------------------------------------
\\
arXiv:2007.01867
replaced with revised version Wed, 8 Jul 2020 20:46:41 GMT   (3129kb,D)

Title: TLIO: Tight Learned Inertial Odometry
Authors: Wenxin Liu, David Caruso, Eddy Ilg, Jing Dong, Anastasios I. Mourikis,
  Kostas Daniilidis, Vijay Kumar, Jakob Engel
Categories: cs.RO cs.CV cs.LG eess.SP
Comments: Corrected typo on author affiliation and removed redundant
  acknowledgements in the footnote
DOI: 10.1109/LRA.2020.3007421
\\ ( https://arxiv.org/abs/2007.01867 ,  3129kb)
------------------------------------------------------------------------------
\\
arXiv:2007.03578 (*cross-listing*)
replaced with revised version Wed, 8 Jul 2020 22:53:16 GMT   (1455kb,D)

Title: A Vision-based Social Distancing and Critical Density Detection System
  for COVID-19
Authors: Dongfang Yang, Ekim Yurtsever, Vishnu Renganathan, Keith A. Redmill,
  \"Umit \"Ozg\"uner
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2007.03578 ,  1455kb)
------------------------------------------------------------------------------
\\
arXiv:2007.03643 (*cross-listing*)
replaced with revised version Wed, 8 Jul 2020 21:26:06 GMT   (6011kb,D)

Title: Segmentation of Pulmonary Opacification in Chest CT Scans of COVID-19
  Patients
Authors: Keegan Lensink, Issam Laradji, Marco Law, Paolo Emilio Barbano, Savvas
  Nicolaou, William Parker, Eldad Haber
Categories: eess.IV cs.CV
Comments: 9 pages, 5 figures. Fix typo in delimiter between author names in
  arXiv metadata
\\ ( https://arxiv.org/abs/2007.03643 ,  6011kb)
------------------------------------------------------------------------------
\\
arXiv:1904.07313
replaced with revised version Thu, 9 Jul 2020 07:28:23 GMT   (5272kb,D)

Title: Combinatorial Conversion and Moment Bisimulation for Stochastic
  Rewriting Systems
Authors: Nicolas Behr, Vincent Danos and Ilias Garnier
Categories: cs.LO cs.DM math-ph math.MP
MSC-class: 16B50, 60J27, 68Q42 (Primary) 60J28, 16B50, 05E99 (Secondary)
ACM-class: F.4.2; G.3; G.2.2
\\ ( https://arxiv.org/abs/1904.07313 ,  5272kb)
------------------------------------------------------------------------------
\\
arXiv:1911.04249
replaced with revised version Thu, 9 Jul 2020 01:09:16 GMT   (23kb)

Title: A polynomial kernel for $3$-leaf power deletion
Authors: Jungho Ahn, Eduard Eiben, O-joung Kwon, and Sang-il Oum
Categories: cs.DS cs.DM math.CO
Comments: 33 pages, 1 figure
\\ ( https://arxiv.org/abs/1911.04249 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:2002.05363 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 05:34:37 GMT   (11kb)

Title: Notes on Tree- and Path-chromatic Number
Authors: Tony Huynh, Bruce Reed, David R. Wood, Liana Yepremyan
Categories: math.CO cs.DM
Comments: 11 pages, 0 figures
MSC-class: 05C83, 05C15, 05C05, 05C10, 05C85
\\ ( https://arxiv.org/abs/2002.05363 ,  11kb)
------------------------------------------------------------------------------
\\
arXiv:2004.00547
replaced with revised version Thu, 9 Jul 2020 09:50:09 GMT   (22kb)

Title: A polynomial time algorithm to compute the connected tree-width of a
  series-parallel graph
Authors: Guillaume Mescoff, Christophe Paul and Dimitrios Thilikos
Categories: cs.DS cs.DM
Comments: 19 pages
\\ ( https://arxiv.org/abs/2004.00547 ,  22kb)
------------------------------------------------------------------------------
\\
arXiv:2007.03984 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 04:29:27 GMT   (27kb)

Title: Asymptotics of the number of 2-threshold functions
Authors: Elena Zamaraeva and Jovisa Zunic
Categories: math.CO cs.DM
Comments: 25 pages
MSC-class: 03B50, 05A18, 52C05, 11P21
ACM-class: G.2.1
\\ ( https://arxiv.org/abs/2007.03984 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2007.03986 (*cross-listing*)
replaced with revised version Thu, 9 Jul 2020 04:31:06 GMT   (28kb)

Title: A characterization of 2-threshold functions via pairs of prime segments
Authors: Elena Zamaraeva and Jovisa Zunic
Categories: math.CO cs.DM
Comments: 19 pages
MSC-class: 05A16, 03B50, 05A18, 52C05, 11P21
ACM-class: G.2.1
\\ ( https://arxiv.org/abs/2007.03986 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:1811.06012
replaced with revised version Wed, 8 Jul 2020 09:14:57 GMT   (2741kb,D)

Title: Opening the Doors to Dynamic Camouflaging: Harnessing the Power of
  Polymorphic Devices
Authors: Nikhil Rangarajan, Satwik Patnaik, Johann Knechtel, Ramesh Karri,
  Ozgur Sinanoglu, and Shaloo Rakheja
Categories: cs.CR cond-mat.mes-hall cs.ET
Comments: Published TETC version; original arxiv preprint found in v1
DOI: 10.1109/TETC.2020.2991134
\\ ( https://arxiv.org/abs/1811.06012 ,  2741kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
